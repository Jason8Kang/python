{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1、xgBoost的基本使用\n",
    "# 2、自定义损失函数的梯度和二阶导\n",
    "# 3、binary:logistic/logitraw\n",
    "\n",
    "\n",
    "# 定义f: theta * x\n",
    "def log_reg(y_hat, y):\n",
    "    p = 1.0 / (1.0 + np.exp(-y_hat))\n",
    "    g = p - y.get_label()\n",
    "    h = p * (1.0-p)\n",
    "    return g, h\n",
    "\n",
    "\n",
    "def error_rate(y_hat, y):\n",
    "    return 'error', float(sum(y.get_label() != (y_hat > 0.5))) / len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xgboost.core.DMatrix object at 0x000000000B1A6A20>\n",
      "<class 'xgboost.core.DMatrix'>\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "data_train = xgb.DMatrix('14.agaricus_train.txt')\n",
    "data_test = xgb.DMatrix('14.agaricus_test.txt')\n",
    "print data_train\n",
    "print type(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-error:0.042831\ttrain-error:0.046522\n",
      "[1]\ttest-error:0.021726\ttrain-error:0.022263\n",
      "[2]\ttest-error:0.006207\ttrain-error:0.007063\n",
      "[3]\ttest-error:0.018001\ttrain-error:0.0152\n",
      "[4]\ttest-error:0.006207\ttrain-error:0.007063\n",
      "[ 0.08073306  0.92217326  0.08073306 ...,  0.98059034  0.01182149\n",
      "  0.98059034]\n",
      "[ 0.  1.  0. ...,  1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# 设置参数\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 0, 'objective': 'binary:logistic'} # logitraw\n",
    "# param = {'max_depth': 3, 'eta': 0.3, 'silent': 1, 'objective': 'reg:logistic'}\n",
    "watchlist = [(data_test, 'test'), (data_train, 'train')]\n",
    "n_round = 5\n",
    "bst = xgb.train(param, data_train, num_boost_round=n_round, evals=watchlist)\n",
    "#bst = xgb.train(param, data_train, num_boost_round=n_round, evals=watchlist, obj=log_reg, feval=error_rate)\n",
    "\n",
    "# 计算错误率\n",
    "y_hat = bst.predict(data_test)\n",
    "y = data_test.get_label()\n",
    "print y_hat\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-error:0.007449\ttrain-error:0.006756\ttest-error:0.007449\ttrain-error:0.006756\n",
      "[1]\ttest-error:0\ttrain-error:0.001228\ttest-error:0\ttrain-error:0.001228\n",
      "[2]\ttest-error:0\ttrain-error:0.001228\ttest-error:0\ttrain-error:0.001228\n",
      "[3]\ttest-error:0\ttrain-error:0.001228\ttest-error:0\ttrain-error:0.001228\n",
      "[4]\ttest-error:0\ttrain-error:0.001228\ttest-error:0\ttrain-error:0.001228\n",
      "[  2.16791759e-05   9.99075532e-01   2.16791759e-05 ...,   9.99183118e-01\n",
      "   2.34865856e-05   9.99183118e-01]\n",
      "[ 0.  1.  0. ...,  1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# 设置参数\n",
    "param = {'max_depth': 4, 'eta': 1, 'silent': 0, 'objective': 'binary:logistic'} # logitraw\n",
    "# param = {'max_depth': 3, 'eta': 0.3, 'silent': 1, 'objective': 'reg:logistic'}\n",
    "watchlist = [(data_test, 'test'), (data_train, 'train')]\n",
    "n_round = 5\n",
    "\n",
    "#bst = xgb.train(param, data_train, num_boost_round=n_round, evals=watchlist)\n",
    "bst = xgb.train(param, data_train, num_boost_round=n_round, evals=watchlist, obj=log_reg, feval=error_rate)\n",
    "\n",
    "# 计算错误率\n",
    "y_hat = bst.predict(data_test)\n",
    "y = data_test.get_label()\n",
    "print y_hat\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数：\t1611\n",
      "错误数目：\t   0\n",
      "错误率：\t0.00000%\n"
     ]
    }
   ],
   "source": [
    "error = sum(y != (y_hat > 0.5))\n",
    "error_rate = float(error) / len(y_hat)\n",
    "print '样本总数：\\t', len(y_hat)\n",
    "print '错误数目：\\t%4d' % error\n",
    "print '错误率：\\t%.5f%%' % (100*error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-merror:0.04\ttrain-merror:0.04\n",
      "[1]\ttest-merror:0.02\ttrain-merror:0.02\n",
      "[2]\ttest-merror:0.04\ttrain-merror:0.01\n",
      "[3]\ttest-merror:0.04\ttrain-merror:0.01\n",
      "[4]\ttest-merror:0.04\ttrain-merror:0.01\n",
      "[5]\ttest-merror:0.04\ttrain-merror:0\n",
      "正确率:\t0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split   # cross_validation\n",
    "\n",
    "\n",
    "def iris_type(s):\n",
    "    it = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
    "    return it[s]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = u'..\\\\10.Regression\\\\10.iris.data'  # 数据文件路径\n",
    "    data = np.loadtxt(path, dtype=float, delimiter=',', converters={4: iris_type})\n",
    "    x, y = np.split(data, (4,), axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=50)\n",
    "\n",
    "    data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "    data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "    watch_list = [(data_test, 'test'), (data_train, 'train')]\n",
    "    param = {'max_depth': 2, 'eta': 1, 'silent': 0, 'obj': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "    bst = xgb.train(param, data_train, num_boost_round=6, evals=watch_list)\n",
    "    y_hat = bst.predict(data_test)\n",
    "    result = y_test.reshape(1, -1) == y_hat\n",
    "    print '正确率:\\t', float(np.sum(result)) / len(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "Logistic回归 正确率：\t0.943820224719\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split   # cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def show_accuracy(a, b, tip):\n",
    "    acc = a.ravel() == b.ravel()\n",
    "    print acc\n",
    "    print tip + '正确率：\\t', float(acc.sum()) / a.size\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = np.loadtxt('14.wine.data', dtype=float, delimiter=',')\n",
    "    y, x = np.split(data, (1,), axis=1)\n",
    "    # x = StandardScaler().fit_transform(x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.5)\n",
    "\n",
    "    # Logistic回归\n",
    "    lr = LogisticRegression(penalty='l2')\n",
    "    lr.fit(x_train, y_train.ravel())\n",
    "    y_hat = lr.predict(x_test)\n",
    "    show_accuracy(y_hat, y_test, 'Logistic回归 ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-merror:0.022472\ttrain-merror:0.022472\n",
      "[1]\ttest-merror:0.022472\ttrain-merror:0.022472\n",
      "[2]\ttest-merror:0.022472\ttrain-merror:0.022472\n",
      "[3]\ttest-merror:0.022472\ttrain-merror:0.022472\n",
      "[4]\ttest-merror:0.022472\ttrain-merror:0.011236\n",
      "[5]\ttest-merror:0.011236\ttrain-merror:0.011236\n",
      "[6]\ttest-merror:0\ttrain-merror:0\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "y_train[y_train == 3] = 0\n",
    "y_test[y_test == 3] = 0\n",
    "data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "watch_list = [(data_test, 'test'), (data_train, 'train')]\n",
    "param = {'max_depth': 2, 'eta': 0.1, 'silent': 0, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "bst = xgb.train(param, data_train, num_boost_round=7, evals=watch_list)\n",
    "y_hat = bst.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "XGBoost 正确率：\t1.0\n"
     ]
    }
   ],
   "source": [
    "show_accuracy(y_hat, y_test, 'XGBoost ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
