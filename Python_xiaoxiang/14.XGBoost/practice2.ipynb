{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    y = []\n",
    "    row = []\n",
    "    col = []\n",
    "    values = []\n",
    "    r = 0       # 首行\n",
    "    for d in open(path):\n",
    "        d = d.strip().split()      # 以空格分开\n",
    "        y.append(int(d[0]))\n",
    "        d = d[1:]\n",
    "        for c in d:\n",
    "            key, value = c.split(':')\n",
    "            row.append(r)\n",
    "            col.append(int(key))\n",
    "            values.append(float(value))\n",
    "        r += 1\n",
    "    x = scipy.sparse.csr_matrix((values, (row, col))).toarray()\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def show_accuracy(a, b, tip):\n",
    "    acc = a.ravel() == b.ravel()\n",
    "    print acc\n",
    "    print tip + '正确率：\\t', float(acc.sum()) / a.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y = read_data('14.agaricus_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1. ...,  1.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6513L, 126L)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print x\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...,  True  True  True]\n",
      "Logistic回归 正确率：\t1.0\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, train_size=0.6)\n",
    "\n",
    "# Logistic回归\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "lr.fit(x_train, y_train.ravel())\n",
    "y_hat = lr.predict(x_test)\n",
    "show_accuracy(y_hat, y_test, 'Logistic回归 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.035687\ttrain-merror:0.040696\n",
      "[1]\teval-merror:0.002686\ttrain-merror:0.003327\n",
      "[2]\teval-merror:0.002686\ttrain-merror:0.003327\n",
      "[3]\teval-merror:0.002686\ttrain-merror:0.003327\n",
      "[4]\teval-merror:0.002686\ttrain-merror:0.003327\n",
      "[5]\teval-merror:0.002686\ttrain-merror:0.003327\n",
      "[6]\teval-merror:0.002686\ttrain-merror:0.003327\n",
      "[7]\teval-merror:0.000767\ttrain-merror:0.001536\n",
      "[8]\teval-merror:0.000767\ttrain-merror:0.001536\n",
      "[9]\teval-merror:0.000767\ttrain-merror:0.001536\n",
      "[ True  True  True ...,  True  True  True]\n",
      "XGBoost 正确率：\t0.999232540292\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "param = {'max_depth': 3, 'eta': 0.2, 'silent': 0, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "bst = xgb.train(param, data_train, num_boost_round=10, evals=watch_list)\n",
    "y_hat = bst.predict(data_test)\n",
    "show_accuracy(y_hat, y_test, 'XGBoost ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林预测缺失年龄：--start--\n",
      "随机森林预测缺失年龄：--over--\n",
      "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642    0.647587   29.665602   \n",
      "std     257.353842    0.486592    0.836071    0.477989   13.737912   \n",
      "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
      "25%     223.500000    0.000000    2.000000    0.000000   21.000000   \n",
      "50%     446.000000    0.000000    3.000000    1.000000   28.000000   \n",
      "75%     668.500000    1.000000    3.000000    1.000000   37.000000   \n",
      "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
      "\n",
      "            SibSp       Parch        Fare  Embarked_C  Embarked_Q  Embarked_S  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean     0.523008    0.381594   32.204208    0.188552    0.086420    0.722783   \n",
      "std      1.102743    0.806057   49.693429    0.391372    0.281141    0.447876   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    7.910400    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000   14.454200    0.000000    0.000000    1.000000   \n",
      "75%      1.000000    0.000000   31.000000    0.000000    0.000000    1.000000   \n",
      "max      8.000000    6.000000  512.329200    1.000000    1.000000    1.000000   \n",
      "\n",
      "       Embarked_U  \n",
      "count  891.000000  \n",
      "mean     0.002245  \n",
      "std      0.047351  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      0.000000  \n",
      "max      1.000000  \n",
      "[0]\teval-error:0.15754\ttrain-error:0.129771\n",
      "[1]\teval-error:0.152154\ttrain-error:0.112708\n",
      "[2]\teval-error:0.140934\ttrain-error:0.101482\n",
      "[3]\teval-error:0.109515\ttrain-error:0.072295\n",
      "[4]\teval-error:0.092011\ttrain-error:0.06062\n",
      "[5]\teval-error:0.083483\ttrain-error:0.05119\n",
      "[6]\teval-error:0.08079\ttrain-error:0.049394\n",
      "[7]\teval-error:0.070467\ttrain-error:0.039515\n",
      "[8]\teval-error:0.065978\ttrain-error:0.03727\n",
      "[9]\teval-error:0.061939\ttrain-error:0.034576\n",
      "[10]\teval-error:0.062388\ttrain-error:0.034127\n",
      "[11]\teval-error:0.060144\ttrain-error:0.029636\n",
      "[12]\teval-error:0.05386\ttrain-error:0.026942\n",
      "[13]\teval-error:0.052065\ttrain-error:0.026493\n",
      "[14]\teval-error:0.05386\ttrain-error:0.026942\n",
      "[15]\teval-error:0.053411\ttrain-error:0.027391\n",
      "[16]\teval-error:0.051167\ttrain-error:0.025146\n",
      "[17]\teval-error:0.048025\ttrain-error:0.021554\n",
      "[18]\teval-error:0.048025\ttrain-error:0.021554\n",
      "[19]\teval-error:0.047127\ttrain-error:0.020207\n",
      "[20]\teval-error:0.043986\ttrain-error:0.018859\n",
      "[21]\teval-error:0.040395\ttrain-error:0.017961\n",
      "[22]\teval-error:0.040844\ttrain-error:0.017512\n",
      "[23]\teval-error:0.039946\ttrain-error:0.016165\n",
      "[24]\teval-error:0.039497\ttrain-error:0.016614\n",
      "[25]\teval-error:0.036355\ttrain-error:0.015267\n",
      "[26]\teval-error:0.033662\ttrain-error:0.013471\n",
      "[27]\teval-error:0.034111\ttrain-error:0.013022\n",
      "[28]\teval-error:0.034111\ttrain-error:0.013022\n",
      "[29]\teval-error:0.032316\ttrain-error:0.012573\n",
      "[30]\teval-error:0.032316\ttrain-error:0.012573\n",
      "[31]\teval-error:0.032316\ttrain-error:0.012573\n",
      "[32]\teval-error:0.032316\ttrain-error:0.012573\n",
      "[33]\teval-error:0.032316\ttrain-error:0.012573\n",
      "[34]\teval-error:0.033214\ttrain-error:0.011675\n",
      "[35]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[36]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[37]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[38]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[39]\teval-error:0.029623\ttrain-error:0.010777\n",
      "[40]\teval-error:0.029623\ttrain-error:0.010777\n",
      "[41]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[42]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[43]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[44]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[45]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[46]\teval-error:0.031418\ttrain-error:0.011226\n",
      "[47]\teval-error:0.029623\ttrain-error:0.010777\n",
      "[48]\teval-error:0.029623\ttrain-error:0.010777\n",
      "[49]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[50]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[51]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[52]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[53]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[54]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[55]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[56]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[57]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[58]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[59]\teval-error:0.026032\ttrain-error:0.009879\n",
      "[60]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[61]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[62]\teval-error:0.027828\ttrain-error:0.010328\n",
      "[63]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[64]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[65]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[66]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[67]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[68]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[69]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[70]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[71]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[72]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[73]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[74]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[75]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[76]\teval-error:0.024237\ttrain-error:0.00943\n",
      "[77]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[78]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[79]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[80]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[81]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[82]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[83]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[84]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[85]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[86]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[87]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[88]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[89]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[90]\teval-error:0.020646\ttrain-error:0.008532\n",
      "[91]\teval-error:0.020646\ttrain-error:0.008532\n",
      "[92]\teval-error:0.020646\ttrain-error:0.008532\n",
      "[93]\teval-error:0.020646\ttrain-error:0.008532\n",
      "[94]\teval-error:0.020646\ttrain-error:0.008532\n",
      "[95]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[96]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[97]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[98]\teval-error:0.022442\ttrain-error:0.008981\n",
      "[99]\teval-error:0.020646\ttrain-error:0.008532\n",
      "随机森林：97.935%\n",
      "XGBoost：97.935%\n"
     ]
    }
   ],
   "source": [
    "# /usr/bin/python\n",
    "# -*- encoding:utf-8 -*-\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "def show_accuracy(a, b, tip):\n",
    "    acc = a.ravel() == b.ravel()\n",
    "    acc_rate = 100 * float(acc.sum()) / a.size\n",
    "    # print '%s正确率：%.3f%%' % (tip, acc_rate)\n",
    "    return acc_rate\n",
    "\n",
    "\n",
    "def load_data(file_name, is_train):\n",
    "    data = pd.read_csv(file_name)  # 数据文件路径\n",
    "    # print 'data.describe() = \\n', data.describe()\n",
    "\n",
    "    # 性别\n",
    "    data['Sex'] = data['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "    # 补齐船票价格缺失值\n",
    "    if len(data.Fare[data.Fare.isnull()]) > 0:\n",
    "        fare = np.zeros(3)\n",
    "        for f in range(0, 3):\n",
    "            fare[f] = data[data.Pclass == f + 1]['Fare'].dropna().median()\n",
    "        for f in range(0, 3):  # loop 0 to 2\n",
    "            data.loc[(data.Fare.isnull()) & (data.Pclass == f + 1), 'Fare'] = fare[f]\n",
    "\n",
    "    # 年龄：使用均值代替缺失值\n",
    "    # mean_age = data['Age'].dropna().mean()\n",
    "    # data.loc[(data.Age.isnull()), 'Age'] = mean_age\n",
    "    if is_train:\n",
    "        # 年龄：使用随机森林预测年龄缺失值\n",
    "        print '随机森林预测缺失年龄：--start--'\n",
    "        data_for_age = data[['Age', 'Survived', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]   # 年龄不缺失的数据\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]\n",
    "        # print age_exist\n",
    "        x = age_exist.values[:, 1:]\n",
    "        y = age_exist.values[:, 0]\n",
    "        rfr = RandomForestRegressor(n_estimators=1000)\n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        # print age_hat\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n",
    "        print '随机森林预测缺失年龄：--over--'\n",
    "    else:\n",
    "        print '随机森林预测缺失年龄2：--start--'\n",
    "        data_for_age = data[['Age', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]  # 年龄不缺失的数据\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]\n",
    "        # print age_exist\n",
    "        x = age_exist.values[:, 1:]\n",
    "        y = age_exist.values[:, 0]\n",
    "        rfr = RandomForestRegressor(n_estimators=1000)\n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        # print age_hat\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n",
    "        print '随机森林预测缺失年龄2：--over--'\n",
    "\n",
    "    # 起始城市\n",
    "    data.loc[(data.Embarked.isnull()), 'Embarked'] = 'S'  # 保留缺失出发城市\n",
    "    # data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2, 'U': 0}).astype(int)\n",
    "    # print data['Embarked']\n",
    "    embarked_data = pd.get_dummies(data.Embarked)\n",
    "    # print embarked_data\n",
    "    # embarked_data = embarked_data.rename(columns={'S': 'Southampton', 'C': 'Cherbourg', 'Q': 'Queenstown', 'U': 'UnknownCity'})\n",
    "    embarked_data = embarked_data.rename(columns=lambda x: 'Embarked_' + str(x))\n",
    "    data = pd.concat([data, embarked_data], axis=1)\n",
    "    print data.describe()\n",
    "    data.to_csv('New_Data.csv')\n",
    "\n",
    "    x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n",
    "    # x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "    y = None\n",
    "    if 'Survived' in data:\n",
    "        y = data['Survived']\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # 思考：这样做，其实发生了什么？\n",
    "    x = np.tile(x, (5, 1))\n",
    "    y = np.tile(y, (5, ))\n",
    "    if is_train:\n",
    "        return x, y\n",
    "    return x, data['PassengerId']\n",
    "\n",
    "\n",
    "def write_result(c, c_type):\n",
    "    file_name = '14.Titanic.test.csv'\n",
    "    x, passenger_id = load_data(file_name, False)\n",
    "\n",
    "    if type == 3:\n",
    "        x = xgb.DMatrix(x)\n",
    "    y = c.predict(x)\n",
    "    y[y > 0.5] = 1\n",
    "    y[~(y > 0.5)] = 0\n",
    "\n",
    "    predictions_file = open(\"Prediction_%d.csv\" % c_type, \"wb\")\n",
    "    open_file_object = csv.writer(predictions_file)\n",
    "    open_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
    "    open_file_object.writerows(zip(passenger_id, y))\n",
    "    predictions_file.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x, y = load_data('14.Titanic.train.csv', True)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=1)\n",
    "    #\n",
    "    # lr = LogisticRegression(penalty='l2')\n",
    "    # lr.fit(x_train, y_train)\n",
    "    # y_hat = lr.predict(x_test)\n",
    "    # lr_rate = show_accuracy(y_hat, y_test, 'Logistic回归 ')\n",
    "    # # write_result(lr, 1)\n",
    "\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(x_train, y_train)\n",
    "    y_hat = rfc.predict(x_test)\n",
    "    rfc_rate = show_accuracy(y_hat, y_test, '随机森林 ')\n",
    "    # write_result(rfc, 2)\n",
    "\n",
    "    # XGBoost\n",
    "    data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "    data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "    watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "    param = {'max_depth': 6, 'eta': 0.8, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "             # 'subsample': 1, 'alpha': 0, 'lambda': 0, 'min_child_weight': 1}\n",
    "    bst = xgb.train(param, data_train, num_boost_round=100, evals=watch_list)\n",
    "    y_hat = bst.predict(data_test)\n",
    "    # write_result(bst, 3)\n",
    "    y_hat[y_hat > 0.5] = 1\n",
    "    y_hat[~(y_hat > 0.5)] = 0\n",
    "    xgb_rate = show_accuracy(y_hat, y_test, 'XGBoost ')\n",
    "\n",
    "    #print 'Logistic回归：%.3f%%' % lr_rate\n",
    "    print '随机森林：%.3f%%' % rfc_rate\n",
    "    print 'XGBoost：%.3f%%' % xgb_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.describe() = \n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
      "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
      "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "file_name = '14.Titanic.train.csv'\n",
    "data = pd.read_csv(file_name)  # 数据文件路径\n",
    "print 'data.describe() = \\n', data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "5      1\n",
       "6      1\n",
       "7      1\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     1\n",
       "13     1\n",
       "14     0\n",
       "15     0\n",
       "16     1\n",
       "17     1\n",
       "18     0\n",
       "19     0\n",
       "20     1\n",
       "21     1\n",
       "22     0\n",
       "23     1\n",
       "24     0\n",
       "25     0\n",
       "26     1\n",
       "27     1\n",
       "28     0\n",
       "29     1\n",
       "      ..\n",
       "861    1\n",
       "862    0\n",
       "863    0\n",
       "864    1\n",
       "865    0\n",
       "866    0\n",
       "867    1\n",
       "868    1\n",
       "869    1\n",
       "870    1\n",
       "871    0\n",
       "872    1\n",
       "873    1\n",
       "874    0\n",
       "875    0\n",
       "876    1\n",
       "877    1\n",
       "878    1\n",
       "879    0\n",
       "880    0\n",
       "881    1\n",
       "882    0\n",
       "883    1\n",
       "884    1\n",
       "885    0\n",
       "886    1\n",
       "887    0\n",
       "888    0\n",
       "889    1\n",
       "890    1\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 性别\n",
    "data['Sex'] = data['Sex'].map({'female': 0, 'male': 1})\n",
    "#equivalant to map(function,list) or use preprocessing\n",
    "data['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#print data.Fare.isnull()\n",
    "print len(data.Fare[data.Fare.isnull()])\n",
    "#equivalant to \n",
    "print sum(data.Fare.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 60.2875,  14.25  ,   8.05  ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fare = np.zeros(3)\n",
    "for f in range(0, 3):\n",
    "    fare[f] = data[data.Pclass == f + 1]['Fare'].dropna().median()\n",
    "for f in range(0, 3):  # loop 0 to 2\n",
    "    data.loc[(data.Fare.isnull()) & (data.Pclass == f + 1), 'Fare'] = fare[f]\n",
    "fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       71.2833\n",
       "3       53.1000\n",
       "6       51.8625\n",
       "11      26.5500\n",
       "23      35.5000\n",
       "27     263.0000\n",
       "30      27.7208\n",
       "31     146.5208\n",
       "34      82.1708\n",
       "35      52.0000\n",
       "52      76.7292\n",
       "54      61.9792\n",
       "55      35.5000\n",
       "61      80.0000\n",
       "62      83.4750\n",
       "64      27.7208\n",
       "83      47.1000\n",
       "88     263.0000\n",
       "92      61.1750\n",
       "96      34.6542\n",
       "97      63.3583\n",
       "102     77.2875\n",
       "110     52.0000\n",
       "118    247.5208\n",
       "124     77.2875\n",
       "136     26.2833\n",
       "137     53.1000\n",
       "139     79.2000\n",
       "151     66.6000\n",
       "155     61.3792\n",
       "         ...   \n",
       "763    120.0000\n",
       "765     77.9583\n",
       "766     39.6000\n",
       "779    211.3375\n",
       "781     57.0000\n",
       "782     30.0000\n",
       "789     79.2000\n",
       "793     30.6958\n",
       "796     25.9292\n",
       "802    120.0000\n",
       "806      0.0000\n",
       "809     53.1000\n",
       "815      0.0000\n",
       "820     93.5000\n",
       "822      0.0000\n",
       "829     80.0000\n",
       "835     83.1583\n",
       "839     29.7000\n",
       "842     31.0000\n",
       "849     89.1042\n",
       "853     39.4000\n",
       "856    164.8667\n",
       "857     26.5500\n",
       "862     25.9292\n",
       "867     50.4958\n",
       "871     52.5542\n",
       "872      5.0000\n",
       "879     83.1583\n",
       "887     30.0000\n",
       "889     30.0000\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.loc[data.Pclass == 1, 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'PassengerId', u'Survived', u'Pclass', u'Name', u'Sex', u'Age',\n",
      "       u'SibSp', u'Parch', u'Ticket', u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object')\n",
      "随机森林预测缺失年龄：--start--\n"
     ]
    }
   ],
   "source": [
    "# 年龄：使用均值代替缺失值\n",
    "# mean_age = data['Age'].dropna().mean()\n",
    "# data.loc[(data.Age.isnull()), 'Age'] = mean_age\n",
    "print data.columns\n",
    "# 年龄：使用随机森林预测年龄缺失值\n",
    "print '随机森林预测缺失年龄：--start--'\n",
    "data_for_age = data[['Age', 'Survived', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "age_exist = data_for_age.loc[(data.Age.notnull())]   # 年龄不缺失的数据\n",
    "age_null = data_for_age.loc[(data.Age.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "      Age  Survived      Fare  Parch  SibSp  Pclass\n",
      "0    22.0         0    7.2500      0      1       3\n",
      "1    38.0         1   71.2833      0      1       1\n",
      "2    26.0         1    7.9250      0      0       3\n",
      "3    35.0         1   53.1000      0      1       1\n",
      "4    35.0         0    8.0500      0      0       3\n",
      "6    54.0         0   51.8625      0      0       1\n",
      "7     2.0         0   21.0750      1      3       3\n",
      "8    27.0         1   11.1333      2      0       3\n",
      "9    14.0         1   30.0708      0      1       2\n",
      "10    4.0         1   16.7000      1      1       3\n",
      "11   58.0         1   26.5500      0      0       1\n",
      "12   20.0         0    8.0500      0      0       3\n",
      "13   39.0         0   31.2750      5      1       3\n",
      "14   14.0         0    7.8542      0      0       3\n",
      "15   55.0         1   16.0000      0      0       2\n",
      "16    2.0         0   29.1250      1      4       3\n",
      "18   31.0         0   18.0000      0      1       3\n",
      "20   35.0         0   26.0000      0      0       2\n",
      "21   34.0         1   13.0000      0      0       2\n",
      "22   15.0         1    8.0292      0      0       3\n",
      "23   28.0         1   35.5000      0      0       1\n",
      "24    8.0         0   21.0750      1      3       3\n",
      "25   38.0         1   31.3875      5      1       3\n",
      "27   19.0         0  263.0000      2      3       1\n",
      "30   40.0         0   27.7208      0      0       1\n",
      "33   66.0         0   10.5000      0      0       2\n",
      "34   28.0         0   82.1708      0      1       1\n",
      "35   42.0         0   52.0000      0      1       1\n",
      "37   21.0         0    8.0500      0      0       3\n",
      "38   18.0         0   18.0000      0      2       3\n",
      "..    ...       ...       ...    ...    ...     ...\n",
      "856  45.0         1  164.8667      1      1       1\n",
      "857  51.0         1   26.5500      0      0       1\n",
      "858  24.0         1   19.2583      3      0       3\n",
      "860  41.0         0   14.1083      0      2       3\n",
      "861  21.0         0   11.5000      0      1       2\n",
      "862  48.0         1   25.9292      0      0       1\n",
      "864  24.0         0   13.0000      0      0       2\n",
      "865  42.0         1   13.0000      0      0       2\n",
      "866  27.0         1   13.8583      0      1       2\n",
      "867  31.0         0   50.4958      0      0       1\n",
      "869   4.0         1   11.1333      1      1       3\n",
      "870  26.0         0    7.8958      0      0       3\n",
      "871  47.0         1   52.5542      1      1       1\n",
      "872  33.0         0    5.0000      0      0       1\n",
      "873  47.0         0    9.0000      0      0       3\n",
      "874  28.0         1   24.0000      0      1       2\n",
      "875  15.0         1    7.2250      0      0       3\n",
      "876  20.0         0    9.8458      0      0       3\n",
      "877  19.0         0    7.8958      0      0       3\n",
      "879  56.0         1   83.1583      1      0       1\n",
      "880  25.0         1   26.0000      1      0       2\n",
      "881  33.0         0    7.8958      0      0       3\n",
      "882  22.0         0   10.5167      0      0       3\n",
      "883  28.0         0   10.5000      0      0       2\n",
      "884  25.0         0    7.0500      0      0       3\n",
      "885  39.0         0   29.1250      5      0       3\n",
      "886  27.0         0   13.0000      0      0       2\n",
      "887  19.0         1   30.0000      0      0       1\n",
      "889  26.0         1   30.0000      0      0       1\n",
      "890  32.0         0    7.7500      0      0       3\n",
      "\n",
      "[714 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#print data.Age.notnull()\n",
    "print type(data_for_age)\n",
    "print data_for_age.loc[(data.Age.notnull())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C    Q    S    U\n",
      "0    0.0  0.0  1.0  0.0\n",
      "1    1.0  0.0  0.0  0.0\n",
      "2    0.0  0.0  1.0  0.0\n",
      "3    0.0  0.0  1.0  0.0\n",
      "4    0.0  0.0  1.0  0.0\n",
      "5    0.0  1.0  0.0  0.0\n",
      "6    0.0  0.0  1.0  0.0\n",
      "7    0.0  0.0  1.0  0.0\n",
      "8    0.0  0.0  1.0  0.0\n",
      "9    1.0  0.0  0.0  0.0\n",
      "10   0.0  0.0  1.0  0.0\n",
      "11   0.0  0.0  1.0  0.0\n",
      "12   0.0  0.0  1.0  0.0\n",
      "13   0.0  0.0  1.0  0.0\n",
      "14   0.0  0.0  1.0  0.0\n",
      "15   0.0  0.0  1.0  0.0\n",
      "16   0.0  1.0  0.0  0.0\n",
      "17   0.0  0.0  1.0  0.0\n",
      "18   0.0  0.0  1.0  0.0\n",
      "19   1.0  0.0  0.0  0.0\n",
      "20   0.0  0.0  1.0  0.0\n",
      "21   0.0  0.0  1.0  0.0\n",
      "22   0.0  1.0  0.0  0.0\n",
      "23   0.0  0.0  1.0  0.0\n",
      "24   0.0  0.0  1.0  0.0\n",
      "25   0.0  0.0  1.0  0.0\n",
      "26   1.0  0.0  0.0  0.0\n",
      "27   0.0  0.0  1.0  0.0\n",
      "28   0.0  1.0  0.0  0.0\n",
      "29   0.0  0.0  1.0  0.0\n",
      "..   ...  ...  ...  ...\n",
      "861  0.0  0.0  1.0  0.0\n",
      "862  0.0  0.0  1.0  0.0\n",
      "863  0.0  0.0  1.0  0.0\n",
      "864  0.0  0.0  1.0  0.0\n",
      "865  0.0  0.0  1.0  0.0\n",
      "866  1.0  0.0  0.0  0.0\n",
      "867  0.0  0.0  1.0  0.0\n",
      "868  0.0  0.0  1.0  0.0\n",
      "869  0.0  0.0  1.0  0.0\n",
      "870  0.0  0.0  1.0  0.0\n",
      "871  0.0  0.0  1.0  0.0\n",
      "872  0.0  0.0  1.0  0.0\n",
      "873  0.0  0.0  1.0  0.0\n",
      "874  1.0  0.0  0.0  0.0\n",
      "875  1.0  0.0  0.0  0.0\n",
      "876  0.0  0.0  1.0  0.0\n",
      "877  0.0  0.0  1.0  0.0\n",
      "878  0.0  0.0  1.0  0.0\n",
      "879  1.0  0.0  0.0  0.0\n",
      "880  0.0  0.0  1.0  0.0\n",
      "881  0.0  0.0  1.0  0.0\n",
      "882  0.0  0.0  1.0  0.0\n",
      "883  0.0  0.0  1.0  0.0\n",
      "884  0.0  0.0  1.0  0.0\n",
      "885  0.0  1.0  0.0  0.0\n",
      "886  0.0  0.0  1.0  0.0\n",
      "887  0.0  0.0  1.0  0.0\n",
      "888  0.0  0.0  1.0  0.0\n",
      "889  1.0  0.0  0.0  0.0\n",
      "890  0.0  1.0  0.0  0.0\n",
      "\n",
      "[891 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 起始城市\n",
    "data.loc[(data.Embarked.isnull()), 'Embarked'] = 'S'  # 保留缺失出发城市\n",
    "# data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2, 'U': 0}).astype(int)\n",
    "#print data['Embarked']\n",
    "embarked_data = pd.get_dummies(data.Embarked)\n",
    "print embarked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Embarked_C', u'Embarked_Q', u'Embarked_S', u'Embarked_U'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# embarked_data = embarked_data.rename(columns={'S': 'Southampton', 'C': 'Cherbourg', 'Q': 'Queenstown', 'U': 'UnknownCity'})\n",
    "embarked_data = embarked_data.rename(columns=lambda x: 'Embarked_' + str(x))\n",
    "print embarked_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  714.000000   \n",
      "mean    446.000000    0.383838    2.308642    0.647587   29.699118   \n",
      "std     257.353842    0.486592    0.836071    0.477990   14.526497   \n",
      "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
      "25%     223.500000    0.000000    2.000000    0.000000         NaN   \n",
      "50%     446.000000    0.000000    3.000000    1.000000         NaN   \n",
      "75%     668.500000    1.000000    3.000000    1.000000         NaN   \n",
      "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
      "\n",
      "            SibSp       Parch        Fare  Embarked_C  Embarked_Q  Embarked_S  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean     0.523008    0.381594   32.204208    0.188552    0.086420    0.722783   \n",
      "std      1.102743    0.806057   49.693429    0.391372    0.281141    0.447876   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    7.910400    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000   14.454200    0.000000    0.000000    1.000000   \n",
      "75%      1.000000    0.000000   31.000000    0.000000    0.000000    1.000000   \n",
      "max      8.000000    6.000000  512.329200    1.000000    1.000000    1.000000   \n",
      "\n",
      "       Embarked_U  \n",
      "count  891.000000  \n",
      "mean     0.002245  \n",
      "std      0.047351  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      0.000000  \n",
      "max      1.000000  \n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([data, embarked_data], axis=1)\n",
    "print data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891L, 9L) (891L,)\n",
      "(4455L, 9L) (4455L,)\n"
     ]
    }
   ],
   "source": [
    "x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n",
    "# x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = None\n",
    "if 'Survived' in data:\n",
    "    y = data['Survived']\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "print x.shape,y.shape\n",
    "# 思考：这样做，其实发生了什么？\n",
    "x = np.tile(x, (5, 1))\n",
    "y = np.tile(y, 5 )\n",
    "print x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
