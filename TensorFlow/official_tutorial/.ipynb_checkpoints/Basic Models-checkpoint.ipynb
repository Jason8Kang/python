{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 Prediction: 3 True Class: 3\n",
      "Test 1 Prediction: 6 True Class: 6\n",
      "Test 2 Prediction: 1 True Class: 1\n",
      "Test 3 Prediction: 1 True Class: 1\n",
      "Test 4 Prediction: 1 True Class: 1\n",
      "Test 5 Prediction: 3 True Class: 3\n",
      "Test 6 Prediction: 9 True Class: 9\n",
      "Test 7 Prediction: 5 True Class: 5\n",
      "Test 8 Prediction: 2 True Class: 2\n",
      "Test 9 Prediction: 9 True Class: 9\n",
      "Test 10 Prediction: 4 True Class: 4\n",
      "Test 11 Prediction: 5 True Class: 5\n",
      "Test 12 Prediction: 9 True Class: 9\n",
      "Test 13 Prediction: 3 True Class: 3\n",
      "Test 14 Prediction: 9 True Class: 9\n",
      "Test 15 Prediction: 0 True Class: 0\n",
      "Test 16 Prediction: 3 True Class: 3\n",
      "Test 17 Prediction: 5 True Class: 6\n",
      "Test 18 Prediction: 5 True Class: 5\n",
      "Test 19 Prediction: 3 True Class: 5\n",
      "Test 20 Prediction: 7 True Class: 7\n",
      "Test 21 Prediction: 2 True Class: 2\n",
      "Test 22 Prediction: 2 True Class: 2\n",
      "Test 23 Prediction: 7 True Class: 7\n",
      "Test 24 Prediction: 1 True Class: 1\n",
      "Test 25 Prediction: 3 True Class: 2\n",
      "Test 26 Prediction: 8 True Class: 8\n",
      "Test 27 Prediction: 4 True Class: 4\n",
      "Test 28 Prediction: 1 True Class: 1\n",
      "Test 29 Prediction: 7 True Class: 7\n",
      "Test 30 Prediction: 3 True Class: 3\n",
      "Test 31 Prediction: 3 True Class: 3\n",
      "Test 32 Prediction: 8 True Class: 8\n",
      "Test 33 Prediction: 8 True Class: 8\n",
      "Test 34 Prediction: 7 True Class: 7\n",
      "Test 35 Prediction: 9 True Class: 9\n",
      "Test 36 Prediction: 2 True Class: 2\n",
      "Test 37 Prediction: 2 True Class: 2\n",
      "Test 38 Prediction: 4 True Class: 4\n",
      "Test 39 Prediction: 1 True Class: 1\n",
      "Test 40 Prediction: 5 True Class: 5\n",
      "Test 41 Prediction: 8 True Class: 9\n",
      "Test 42 Prediction: 8 True Class: 8\n",
      "Test 43 Prediction: 7 True Class: 7\n",
      "Test 44 Prediction: 2 True Class: 2\n",
      "Test 45 Prediction: 1 True Class: 3\n",
      "Test 46 Prediction: 0 True Class: 0\n",
      "Test 47 Prediction: 6 True Class: 4\n",
      "Test 48 Prediction: 4 True Class: 4\n",
      "Test 49 Prediction: 2 True Class: 2\n",
      "Test 50 Prediction: 9 True Class: 4\n",
      "Test 51 Prediction: 1 True Class: 1\n",
      "Test 52 Prediction: 9 True Class: 9\n",
      "Test 53 Prediction: 5 True Class: 5\n",
      "Test 54 Prediction: 7 True Class: 7\n",
      "Test 55 Prediction: 7 True Class: 7\n",
      "Test 56 Prediction: 2 True Class: 2\n",
      "Test 57 Prediction: 8 True Class: 8\n",
      "Test 58 Prediction: 2 True Class: 2\n",
      "Test 59 Prediction: 6 True Class: 6\n",
      "Test 60 Prediction: 8 True Class: 8\n",
      "Test 61 Prediction: 5 True Class: 5\n",
      "Test 62 Prediction: 7 True Class: 7\n",
      "Test 63 Prediction: 7 True Class: 7\n",
      "Test 64 Prediction: 4 True Class: 9\n",
      "Test 65 Prediction: 1 True Class: 1\n",
      "Test 66 Prediction: 8 True Class: 8\n",
      "Test 67 Prediction: 1 True Class: 1\n",
      "Test 68 Prediction: 5 True Class: 8\n",
      "Test 69 Prediction: 0 True Class: 0\n",
      "Test 70 Prediction: 3 True Class: 3\n",
      "Test 71 Prediction: 0 True Class: 0\n",
      "Test 72 Prediction: 1 True Class: 1\n",
      "Test 73 Prediction: 9 True Class: 9\n",
      "Test 74 Prediction: 9 True Class: 9\n",
      "Test 75 Prediction: 4 True Class: 4\n",
      "Test 76 Prediction: 1 True Class: 1\n",
      "Test 77 Prediction: 8 True Class: 8\n",
      "Test 78 Prediction: 2 True Class: 2\n",
      "Test 79 Prediction: 1 True Class: 1\n",
      "Test 80 Prediction: 2 True Class: 2\n",
      "Test 81 Prediction: 9 True Class: 9\n",
      "Test 82 Prediction: 7 True Class: 7\n",
      "Test 83 Prediction: 5 True Class: 5\n",
      "Test 84 Prediction: 9 True Class: 9\n",
      "Test 85 Prediction: 2 True Class: 2\n",
      "Test 86 Prediction: 6 True Class: 6\n",
      "Test 87 Prediction: 4 True Class: 4\n",
      "Test 88 Prediction: 1 True Class: 1\n",
      "Test 89 Prediction: 5 True Class: 5\n",
      "Test 90 Prediction: 9 True Class: 8\n",
      "Test 91 Prediction: 2 True Class: 2\n",
      "Test 92 Prediction: 9 True Class: 9\n",
      "Test 93 Prediction: 2 True Class: 2\n",
      "Test 94 Prediction: 0 True Class: 0\n",
      "Test 95 Prediction: 4 True Class: 4\n",
      "Test 96 Prediction: 0 True Class: 0\n",
      "Test 97 Prediction: 0 True Class: 0\n",
      "Test 98 Prediction: 2 True Class: 2\n",
      "Test 99 Prediction: 8 True Class: 8\n",
      "Test 100 Prediction: 1 True Class: 4\n",
      "Test 101 Prediction: 7 True Class: 7\n",
      "Test 102 Prediction: 1 True Class: 1\n",
      "Test 103 Prediction: 7 True Class: 2\n",
      "Test 104 Prediction: 9 True Class: 4\n",
      "Test 105 Prediction: 0 True Class: 0\n",
      "Test 106 Prediction: 2 True Class: 2\n",
      "Test 107 Prediction: 7 True Class: 7\n",
      "Test 108 Prediction: 4 True Class: 4\n",
      "Test 109 Prediction: 3 True Class: 3\n",
      "Test 110 Prediction: 3 True Class: 3\n",
      "Test 111 Prediction: 0 True Class: 0\n",
      "Test 112 Prediction: 0 True Class: 0\n",
      "Test 113 Prediction: 3 True Class: 3\n",
      "Test 114 Prediction: 1 True Class: 1\n",
      "Test 115 Prediction: 9 True Class: 9\n",
      "Test 116 Prediction: 6 True Class: 6\n",
      "Test 117 Prediction: 5 True Class: 5\n",
      "Test 118 Prediction: 0 True Class: 2\n",
      "Test 119 Prediction: 5 True Class: 5\n",
      "Test 120 Prediction: 1 True Class: 9\n",
      "Test 121 Prediction: 7 True Class: 2\n",
      "Test 122 Prediction: 9 True Class: 9\n",
      "Test 123 Prediction: 3 True Class: 3\n",
      "Test 124 Prediction: 0 True Class: 0\n",
      "Test 125 Prediction: 9 True Class: 4\n",
      "Test 126 Prediction: 1 True Class: 2\n",
      "Test 127 Prediction: 0 True Class: 0\n",
      "Test 128 Prediction: 7 True Class: 7\n",
      "Test 129 Prediction: 1 True Class: 1\n",
      "Test 130 Prediction: 1 True Class: 1\n",
      "Test 131 Prediction: 2 True Class: 2\n",
      "Test 132 Prediction: 1 True Class: 1\n",
      "Test 133 Prediction: 5 True Class: 5\n",
      "Test 134 Prediction: 3 True Class: 3\n",
      "Test 135 Prediction: 3 True Class: 3\n",
      "Test 136 Prediction: 9 True Class: 9\n",
      "Test 137 Prediction: 7 True Class: 7\n",
      "Test 138 Prediction: 3 True Class: 8\n",
      "Test 139 Prediction: 6 True Class: 6\n",
      "Test 140 Prediction: 5 True Class: 5\n",
      "Test 141 Prediction: 6 True Class: 6\n",
      "Test 142 Prediction: 1 True Class: 1\n",
      "Test 143 Prediction: 3 True Class: 3\n",
      "Test 144 Prediction: 8 True Class: 8\n",
      "Test 145 Prediction: 1 True Class: 1\n",
      "Test 146 Prediction: 0 True Class: 0\n",
      "Test 147 Prediction: 5 True Class: 5\n",
      "Test 148 Prediction: 1 True Class: 1\n",
      "Test 149 Prediction: 3 True Class: 3\n",
      "Test 150 Prediction: 1 True Class: 1\n",
      "Test 151 Prediction: 5 True Class: 5\n",
      "Test 152 Prediction: 5 True Class: 5\n",
      "Test 153 Prediction: 6 True Class: 6\n",
      "Test 154 Prediction: 1 True Class: 1\n",
      "Test 155 Prediction: 8 True Class: 8\n",
      "Test 156 Prediction: 5 True Class: 5\n",
      "Test 157 Prediction: 1 True Class: 1\n",
      "Test 158 Prediction: 4 True Class: 7\n",
      "Test 159 Prediction: 9 True Class: 9\n",
      "Test 160 Prediction: 4 True Class: 4\n",
      "Test 161 Prediction: 6 True Class: 6\n",
      "Test 162 Prediction: 2 True Class: 2\n",
      "Test 163 Prediction: 1 True Class: 2\n",
      "Test 164 Prediction: 5 True Class: 5\n",
      "Test 165 Prediction: 0 True Class: 0\n",
      "Test 166 Prediction: 6 True Class: 6\n",
      "Test 167 Prediction: 5 True Class: 5\n",
      "Test 168 Prediction: 6 True Class: 6\n",
      "Test 169 Prediction: 5 True Class: 3\n",
      "Test 170 Prediction: 7 True Class: 7\n",
      "Test 171 Prediction: 2 True Class: 2\n",
      "Test 172 Prediction: 0 True Class: 0\n",
      "Test 173 Prediction: 8 True Class: 8\n",
      "Test 174 Prediction: 8 True Class: 8\n",
      "Test 175 Prediction: 5 True Class: 5\n",
      "Test 176 Prediction: 9 True Class: 4\n",
      "Test 177 Prediction: 1 True Class: 1\n",
      "Test 178 Prediction: 1 True Class: 1\n",
      "Test 179 Prediction: 4 True Class: 4\n",
      "Test 180 Prediction: 0 True Class: 0\n",
      "Test 181 Prediction: 7 True Class: 3\n",
      "Test 182 Prediction: 3 True Class: 3\n",
      "Test 183 Prediction: 7 True Class: 7\n",
      "Test 184 Prediction: 6 True Class: 6\n",
      "Test 185 Prediction: 1 True Class: 1\n",
      "Test 186 Prediction: 6 True Class: 6\n",
      "Test 187 Prediction: 2 True Class: 2\n",
      "Test 188 Prediction: 1 True Class: 1\n",
      "Test 189 Prediction: 9 True Class: 9\n",
      "Test 190 Prediction: 2 True Class: 2\n",
      "Test 191 Prediction: 8 True Class: 8\n",
      "Test 192 Prediction: 6 True Class: 6\n",
      "Test 193 Prediction: 1 True Class: 1\n",
      "Test 194 Prediction: 9 True Class: 9\n",
      "Test 195 Prediction: 5 True Class: 5\n",
      "Test 196 Prediction: 2 True Class: 2\n",
      "Test 197 Prediction: 5 True Class: 5\n",
      "Test 198 Prediction: 4 True Class: 4\n",
      "Test 199 Prediction: 4 True Class: 4\n",
      "Done!\n",
      "Accuracy: 0.8800000000000007\n"
     ]
    }
   ],
   "source": [
    "# In this example, we limit mnist data\n",
    "Xtr, Ytr = mnist.train.next_batch(5000) #5000 for training (nn candidates)\n",
    "Xte, Yte = mnist.test.next_batch(200) #200 for testing\n",
    "\n",
    "# tf Graph Input\n",
    "xtr = tf.placeholder(\"float\", [None, 784])\n",
    "xte = tf.placeholder(\"float\", [784])\n",
    "\n",
    "# Nearest Neighbor calculation using L1 Distance\n",
    "# Calculate L1 Distance\n",
    "distance = tf.reduce_sum(tf.abs(tf.add(xtr, tf.negative(xte))), reduction_indices=1)\n",
    "# Prediction: Get min distance index (Nearest neighbor)\n",
    "pred = tf.arg_min(distance, 0)\n",
    "\n",
    "accuracy = 0.\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # loop over test data\n",
    "    for i in range(len(Xte)):\n",
    "        # Get nearest neighbor\n",
    "        nn_index = sess.run(pred, feed_dict={xtr: Xtr, xte: Xte[i, :]})\n",
    "        # Get nearest neighbor class label and compare it to its true label\n",
    "        print(\"Test\", i, \"Prediction:\", np.argmax(Ytr[nn_index]), \\\n",
    "            \"True Class:\", np.argmax(Yte[i]))\n",
    "        # Calculate accuracy\n",
    "        if np.argmax(Ytr[nn_index]) == np.argmax(Yte[i]):\n",
    "            accuracy += 1./len(Xte)\n",
    "    print(\"Done!\")\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: 'https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/' already in 'channels' list, moving to the top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-2.0.0-cp35-cp35m-win_amd64.whl (9.0MB)\n",
      "Collecting pytz (from matplotlib)\n",
      "  Downloading pytz-2016.10-py2.py3-none-any.whl (483kB)\n",
      "Collecting python-dateutil (from matplotlib)\n",
      "  Downloading python_dateutil-2.6.0-py2.py3-none-any.whl (194kB)\n",
      "Requirement already satisfied: numpy>=1.7.1 in c:\\users\\jason\\anaconda2\\envs\\env-tf\\lib\\site-packages (from matplotlib)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in c:\\users\\jason\\anaconda2\\envs\\env-tf\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\jason\\anaconda2\\envs\\env-tf\\lib\\site-packages (from matplotlib)\n",
      "Installing collected packages: pytz, python-dateutil, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 matplotlib-2.0.0 python-dateutil-2.6.0 pytz-2016.10\n"
     ]
    }
   ],
   "source": [
    "!conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 0.462030053 W= 0.596358 b= -1.69313\n",
      "Epoch: 0100 cost= 0.417562693 W= 0.575734 b= -1.54476\n",
      "Epoch: 0150 cost= 0.378229380 W= 0.556337 b= -1.40522\n",
      "Epoch: 0200 cost= 0.343437254 W= 0.538093 b= -1.27398\n",
      "Epoch: 0250 cost= 0.312662274 W= 0.520935 b= -1.15054\n",
      "Epoch: 0300 cost= 0.285440326 W= 0.504797 b= -1.03445\n",
      "Epoch: 0350 cost= 0.261361241 W= 0.489619 b= -0.925259\n",
      "Epoch: 0400 cost= 0.240062580 W= 0.475343 b= -0.822562\n",
      "Epoch: 0450 cost= 0.221223295 W= 0.461917 b= -0.725974\n",
      "Epoch: 0500 cost= 0.204559430 W= 0.449289 b= -0.63513\n",
      "Epoch: 0550 cost= 0.189819768 W= 0.437412 b= -0.549689\n",
      "Epoch: 0600 cost= 0.176782325 W= 0.426242 b= -0.469329\n",
      "Epoch: 0650 cost= 0.165250435 W= 0.415736 b= -0.39375\n",
      "Epoch: 0700 cost= 0.155050308 W= 0.405855 b= -0.322664\n",
      "Epoch: 0750 cost= 0.146028265 W= 0.396561 b= -0.255807\n",
      "Epoch: 0800 cost= 0.138048261 W= 0.38782 b= -0.192926\n",
      "Epoch: 0850 cost= 0.130989939 W= 0.379599 b= -0.133785\n",
      "Epoch: 0900 cost= 0.124746956 W= 0.371867 b= -0.0781614\n",
      "Epoch: 0950 cost= 0.119225107 W= 0.364595 b= -0.0258458\n",
      "Epoch: 1000 cost= 0.114341140 W= 0.357755 b= 0.0233584\n",
      "Optimization Finished!\n",
      "Training cost= 0.114341 W= 0.357755 b= 0.0233584 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VOXZ//HPRUBCWEQRqwJhIqCACEECilQrsoiAS1EU\nH2rVx4oLVfrUDY0LLlGsVmt/LjyxWPRnqlUsSgWtCyAoiiyCbCpEAsYVUBCMSCD388eEITNMyEwy\nyTkz+b5fr7ySc8+ZmYsA39w55z7XMeccIiKSWhp4XYCIiCSewl1EJAUp3EVEUpDCXUQkBSncRURS\nkMJdRCQFKdxFRFKQwl1EJAXFHO5mlmZmH5rZK1Eea2xm/zSztWa2wMwCiSxSRETi0zCOfccBq4EW\nUR67FPjeOdfRzEYB9wHn7+/FDjnkEBcIBOJ4exERWbx48SbnXOuq9osp3M2sLTAMyAP+GGWXs4AJ\n5V9PBR4xM3P76W0QCARYtGhRLG8vIiLlzGx9LPvFeljmL8ANQFklj7cBPgdwzu0CtgKtYnxtERFJ\nsCrD3cyGA9865xbX9M3MbIyZLTKzRRs3bqzpy4mISCVimbn3A840syLgOeBUM3smYp8vgHYAZtYQ\nOBDYHPlCzrl851yOcy6ndesqDxmJiEg1VXnM3Tl3E3ATgJmdAlznnPtNxG7TgYuA94BzgVn7O95e\nmdLSUoqLi9mxY0e8T5VakJ6eTtu2bWnUqJHXpYhInOJZLRPGzO4EFjnnpgOTgf9vZmuB74BR1XnN\n4uJimjdvTiAQwMyqW5okgHOOzZs3U1xcTFZWltfliEic4gp359wcYE7517dVGN8BjKxpMTt27FCw\n+4SZ0apVK3RuRCQ5+e4KVQW7f+jvQiR5+S7cRURS1Y7S3Tz4xqd8ueWnWn8vhXuE4uJizjrrLDp1\n6kSHDh0YN24cO3fujLrvl19+ybnnnlvlaw4dOpQtW7ZUq54JEybwwAMPVLlfs2bN9vv4li1beOyx\nx6pVg4jU3POLPqfzra/x17fWMPfT2j/cmdzhXlAAgQA0aBD8XFBQo5dzzjFixAjOPvts1qxZw6ef\nfsr27dvJzc3dZ99du3ZxxBFHMHXq1Cpfd+bMmbRs2bJGtdWUwl3EG1t/KiUwfgY3TP0IgLOzj2BU\nn8xaf9/kDfeCAhgzBtavB+eCn8eMqVHAz5o1i/T0dC655BIA0tLSeOihh3jyyScpKSlhypQpjBw5\nkjPOOIPBgwdTVFREt27dACgpKeG8886je/funH/++Rx//PGh9gqBQIBNmzZRVFREly5duOyyyzjm\nmGMYPHgwP/0U/PXsiSeeoHfv3vTo0YNzzjmHkpKS/da6bt06+vbtS+/evbn11ltD49u3b2fAgAEc\nd9xxHHvssbz88ssAjB8/nsLCQrKzs7n++usr3U9EEmfS24X0uOP10Pbc6/vzl1E96+S9kzfcc3Mh\nMgBLSoLj1bRy5Up69eoVNtaiRQsyMzNZu3YtAO+99x5PPfUUs2bNCtvvscce46CDDuKjjz7i1ltv\nZfHi6Bf0rlmzhrFjx7Jy5UpatmzJiy++CMCIESNYuHAhy5Yto0uXLkyePHm/tY4bN44rr7yShQsX\ncthhh4XG09PTmTZtGkuWLGH27Nlce+21OOeYOHEiHTp0YOnSpdx///2V7iciNfftDzsIjJ/BxFc/\nBuDyk4+kaOIwMltl1FkN1V7n7rkNG+IbT5BBgwZx8MEH7zP+zjvvMG7cOAC6detG9+7doz4/KyuL\n7OxsAHr16kVRUREAK1as4JZbbmHLli1s376d0047bb91vPvuu6EfDBdeeCE33ngjEDy0dPPNNzN3\n7lwaNGjAF198wTfffLPP8yvbr+IPChGJ312vrGLyO+tC2wtzB9K6eeM6ryN5wz0zM3goJtp4NXXt\n2nWfY+g//PADGzZsoGPHjixZsoSmTZtW+/UBGjfe+5eclpYWOixz8cUX89JLL9GjRw+mTJnCnDlz\nqnytaEsVCwoK2LhxI4sXL6ZRo0YEAoGoV/zGup+IxKZo04+c8sCc0Hbu0C5cdvKRntWTvIdl8vIg\nI+JXnIyM4Hg1DRgwgJKSEp5++mkAdu/ezbXXXsvFF19MRuR7RejXrx/PP/88AKtWrWL58uVxvfe2\nbds4/PDDKS0tpSCG8wb9+vXjueeeAwjbf+vWrRx66KE0atSI2bNns778B2Dz5s3Ztm1blfuJSPyu\nfvbDsGD/aMJgT4MdkjncR4+G/Hxo3x7Mgp/z84Pj1WRmTJs2jRdeeIFOnTpx1FFHkZ6ezj333FPl\nc6+66io2btxI9+7due++++jevTsHHnhgzO991113cfzxxzNo0CA6d+5c5f4PP/wwjz76KL1792br\n1q2h8dGjR7No0SJycnIoKCgIvVarVq3o168f3bp14/rrr690PxGJ3YovthIYP4N/L/sSgAdG9qBo\n4jBapHvfj8m8OomWk5PjIm/WsXr1arp06eJJPTW1e/duSktLSU9Pp7CwkIEDB/LJJ59wwAEHeF1a\njSTz34lIbSkrc4zKf58Pir4D4KCMRrx30wDSG6XV+nub2WLnXE5V+yXvMXefKSkpoX///pSWluKc\n47HHHkv6YBeRfc0v3MR/PbEgtP3kxTmc2vkXHlYUncI9QZo3b67bBoqksNLdZQx88G3Wbw4uwe58\nWHNmXHMSaQ382YNJ4S4iUoXXVnzFFc8sCW1PvaIvOYF9l0T7icJdRKQSP+3cTc+7XmdHafD20Scf\n1ZqnLumdFB1TFe4iIlH8Y8EGbp62d0nzf/5wMkcf1tzDiuKjcBcRqWBLyU6y73wjtD2yV1vuH9nD\nw4qqJ3nXudeStLQ0srOzQx9FRUUsWrSIa665BoA5c+Ywf/780P4vvfQSq1ativt9KmvRu2c81nbC\nIpI4j8xaExbs827on5TBDpq576NJkyYsXbo0bCwQCJCTE1xWOmfOHJo1a8aJJ54IBMN9+PDhdO3a\nNaF1xNpOWERq7uutOzjh3rdC22P7d+D605L7wj7N3GMwZ84chg8fTlFREZMmTeKhhx4iOzubt99+\nm+nTp3P99deTnZ1NYWEhhYWFDBkyhF69enHSSSfx8cfBrnCVteitTMV2wlOmTGHEiBEMGTKETp06\nccMNN4T2e/311+nbty/HHXccI0eOZPv27bXzTRBJUbe/vCIs2BffMjDpgx18PHO/498rWfXlDwl9\nza5HtOD2M47Z7z4//fRTqGtjVlYW06ZNCz0WCAS44ooraNasGddddx0AZ555JsOHDw8dQhkwYACT\nJk2iU6dOLFiwgKuuuopZs2aFWvT+9re/5dFHH4279qVLl/Lhhx/SuHFjjj76aK6++mqaNGnC3Xff\nzZtvvknTpk257777ePDBB7ntttuqfkGReq5w43YG/Pnt0PZtw7vy37/M8rCixPJtuHsl2mGZWG3f\nvp358+czcuTI0NjPP/8MVN6iN1YDBgwI9arp2rUr69evZ8uWLaxatYp+/foBsHPnTvr27Vut2kXq\nC+ccVz6zhNdWfh0aW3HHaTRrnFpx6Ns/TVUzbD8qKyujZcuWlf5wqMna2MhWwbt27cI5x6BBg3j2\n2Wer/boi9clHxVs485F3Q9sPj8rmrOw2HlZUe6o85m5m6Wb2gZktM7OVZnZHlH0uNrONZra0/ON3\ntVOu9yJb51bcbtGiBVlZWbzwwgtAcIawbNkyoPIWvTVxwgkn8O6774buEvXjjz/y6aefJuS1RVJJ\nWZnj7EffDQX7oc0b88ndQ1I22CG2E6o/A6c653oA2cAQMzshyn7/dM5ll3/8LaFV+sgZZ5zBtGnT\nyM7OZt68eYwaNYr777+fnj17UlhYSEFBAZMnT6ZHjx4cc8wxoXuTVtaityZat27NlClTuOCCC+je\nvTt9+/YNncAVkaB/LNjAkTfPZOnnWwCYcklvPsgdSOOGtd/B0Utxtfw1swzgHeBK59yCCuMXAznO\nud/H+lqp1vI3VenvRJJVyc5ddL3tP6HtY9scyEtj+/m20VesYm35G9NSSDNLM7OlwLfAGxWDvYJz\nzOwjM5tqZu3irFdEJGGuKlgcFuwTzujKv6/+pffBXlAAgQA0aBD8nKBDtNHEdELVObcbyDazlsA0\nM+vmnFtRYZd/A8865342s8uBp4BTI1/HzMYAYwAya3CvUxGRaDZt/5mcu98MG1t371B/NPoqKIAx\nY6Ak2DKY9euD21CjO8hVJq6LmJxzW4DZwJCI8c3OuZ/LN/8G9Krk+fnOuRznXE7r1q0re494SpJa\npL8LSSZD/jI3LNgfH30cRROH+SPYAXJz9wb7HiUlwfFaUOXM3cxaA6XOuS1m1gQYBNwXsc/hzrmv\nyjfPBFZXp5j09HQ2b95Mq1at/PMXUk8559i8eTPp6elelyKyX59t3M6pFS5GAiiaOMyjavZjw4b4\nxmsolsMyhwNPmVkawZn+8865V8zsTmCRc246cI2ZnQnsAr4DLq5OMW3btqW4uJiNGzdW5+mSYOnp\n6bRt29brMkQqFRg/I2z7xSv70qu9T2+ikZkZPBQTbbwW+OoG2SIisVi8/jvOefy9sDFfztYrijzm\nDpCRAfn5cR1zT+hqGRERvwiMnxEW7G9d+6vKg70OV6dUafToYJC3bw9mwc9xBns8fNt+QESkosj7\nmHY6tBlv/PFXlT+hjlenxGT06Dp7bx2WERFfc86RddPMsLGFuQNp3bxxJc8oFwhEP8bdvj0UFSWs\nvroW62EZzdxFxLf+/u467vj33judnd7tMB7/TdSV1vuq49UpfqNwFxHf+XnXbo6+5bWwsVV3nkbG\nAXFEVh2vTvEbnVAVEV8Z8Oc5YcF+xa86UDRxWHzBDpCXF1yNUlFGRnC8HtDMXUR84fsfd9LzrjfC\nxtbknU6jtGrOQfecuMzNDR6KycwMBrtXJ1PrmMJdRDwXeTHSeTlt+dO5PWr+wnW4OsVvFO4i4plo\nrQN80+grySncRcQTkbP13KFduOzkIz2qJvUo3EWkTr3/2WZG5b8fNub71gFJSOEuInUmcrb+vxf2\n4rRjDvOomtSmpZAi8fBTr5Ik8uLi4n2CvWjiMAV7LdLMXSRWfuxVkgQiQ3367/vRvW1Lj6qpPzRz\nF4lVHd9JJ9k98J9Pos7WFex1QzN3kVjV814lsSorcxx5c3ijr3fHn0qblk08qqh+UriLxKqe9yqJ\nxWVPL+KNVd+Etps0SmP1XUP28wypLQp3kVjl5UW/k0496VWyPztKd9P51vBGX8snDKZ5eiOPKhKF\nu0is6nmvksqceO9bfLl1R2i7T9bBPH95Xw8rElC4i8SnHvcqibRx28/0znszbGxt3uk0rG6jL0ko\nhbuIxC1yFcxv+7bnzrO6eVSNRKNwF5GYffrNNgY/NDdsTK0D/EnhLiIxiZyt33HmMVx0YsCbYqRK\nVYa7maUDc4HG5ftPdc7dHrFPY+BpoBewGTjfOVeU8GpFpM7NW7ORCyd/EDam2br/xTJz/xk41Tm3\n3cwaAe+Y2avOuYpt3S4FvnfOdTSzUcB9wPm1UK+I1KHI2frfL+5N/86HelSNxKPKcHfOOWB7+Waj\n8g8XsdtZwITyr6cCj5iZlT9XRJLMsx9s4KZ/LQ8b02w9ucR0zN3M0oDFQEfgUefcgohd2gCfAzjn\ndpnZVqAVsCmBtYpIHYicrc+85iS6HtHCo2qkumIKd+fcbiDbzFoC08ysm3NuRbxvZmZjgDEAmbpk\nW8RX8mas4ol568LGNFtPXnFdbeCc2wLMBiKbRXwBtAMws4bAgQRPrEY+P985l+Ocy2ndunX1KhaR\nhNpd5giMnxEW7AtuHuBtsKtvfo3FslqmNVDqnNtiZk2AQQRPmFY0HbgIeA84F5il4+0i/nfh5AXM\nW7P36OnBTQ9gya2DPKwI9c1PkFhm7ocDs83sI2Ah8IZz7hUzu9PMzizfZzLQyszWAn8ExtdOuSIS\ntyiz4JKduwiMnxEW7KvuPM37YAf1zU8Q82qCnZOT4xYtWuTJe4vUG5GzYKDnNf/g+yZ7T5CefFRr\nnv7vPl5UF12DBhAtl8ygrKzu6/EZM1vsnMupaj9doSqSyirMgr9u1ooTxj4V9nDhPUNJa2BeVFY5\n9c1PCIW7SCorv0tU4MZXwoYvX/AiN81+0ouKqqa++QmhcBdJYe/3OpVRA/4nbKzovuHQvr1HFcVA\nffMTQo2XRWqLx8v5AuNnhAX72Pn/DAZ7MsyCR4+GoqLgMfaiIgV7NWjmLlIbPFzO99wHGxgf2Trg\nubHBWXD79poF1xNaLSNSGwKB6CcF27cPzkRr620jWgc8PCqbs7Lb1Nr7Sd3TahkRL5WfyIx5vIYm\nTF/JlPlFYWNqHVC/6Zh7faHLuetWZcv2Erycz7lg64CKwf6vq05UsItm7vWCLueue3WwnO/Xj73L\nhxu2hI0p1GUPHXOvDzw6/lvvFRTUynK+0t1ldMp9NWxs/vhTOaJlkxq/tvhfrMfcFe71gS7nThmR\nJ0xBs/X6RidUZS9dzp30Nm77md55b4aNrbzjNJo21n9hiU7/MuoDXc6d1DRbl+pQuNcHupw7Ka34\nYivD/987YWO+bPQlvqRwry9Gj1aYJ5HI2fqRrZsy69pTvClGkpLCXcRHpi/7kmue/TBsTIdgpDoU\n7iI+ETlbv6BPO+4d0d2jaiTZKdxFPHbfax/z+JzCsDHN1qWm1H5AUp+PWy8Exs8IC/a8X3dTsEtC\naOYuqc2nrRfOm/QeHxR9FzamUJdE0hWqktp81nrBOUfWTTPDxp6/vC99sg6u81okOekKVRGo89a7\n+6OLkaQu6Zi7pLY6ar27PztKd+8T7O/c2D/+YPfxuQPxnyrD3czamdlsM1tlZivNbFyUfU4xs61m\ntrT847baKVckTnl5wVYLFdVh64XA+Bl0vvW1sLGiicNoe1BGJc+oxJ5zB+vXB5vA7Tl3oICXSsRy\nWGYXcK1zbomZNQcWm9kbzrlVEfvNc84NT3yJIjXgUeuFr7b+RN97Z4WNrbrzNDIOqOaR0Nzc8N5A\nENzOzdWVxxJVlf/SnHNfAV+Vf73NzFYDbYDIcBfxpzpuvVArx9Z9dO5AkkNc0wgzCwA9gQVRHu5r\nZsuAL4HrnHMra1ydSBJ5Z80mfjM5/L/GunuHYpaARl9q2yxxijnczawZ8CLwB+fcDxEPLwHaO+e2\nm9lQ4CWgU5TXGAOMAcjUP0pJIZGz9W5tWvDK1Scl7g3UtlniFNM6dzNrBLwC/Mc592AM+xcBOc65\nTZXto3Xukgry5xZyz8yPw8ZqbXljLd22T5JLrOvcY1ktY8BkYHVlwW5mh5Xvh5n1KX/dzfGVLFJB\nEiz7C4yfERbsw449vHbXrY8eHbzwqqws+FnBLvsRy2GZfsCFwHIzW1o+djOQCeCcmwScC1xpZruA\nn4BRzqtLXyX5+bRlwB6/e2oRb67+JmxMFyOJ36j9gPiPz1oGVBR5bP224V35719meVSN1EdqPyDJ\ny4fL/jrlzqR0d/hESLN18TOFu/iPj5b9lZU5jrw5vNHXPy47nhM7HFLntYjEQ+Eu/uOTZX9q9CXJ\nTOEu/uNRy4A9fthRSvcJr4eNvXNj//j7wYh4SOEu/lTHLQP20GxdUoXCXQRY++12Bj74dtjY6juH\n0OSANI8qEqkZhbvUe5qtSypSuEu99eaqb/jd0+HXWiSs0ZeIxxTuUi9FztYPPzCd924a4FE1Iomn\ncJd65aE3PuXht9aEjekQjKQihbvUG5Gz9fNy2vKnc3t4VI1I7VK4S8q77oVlTF1cHDam2bqkOoW7\npLTI2fq9I47lgj66UYykPoW7pKST/zSbDd+F31Bas3WpTxTuklJ2lzk6RDT6mnnNSXQ9ooVHFYl4\nQ+EuKUMXI4nspXCXpLf1p1J63BHe6GvxLQNp1ayxRxWJeE/hLklNs3WR6Kq8QbZIravGzbALN27f\nJ9g/vft0BbtIOc3cxVvVuBl2ZKg3a9yQFXecVptViiQd3SBbvBXHzbDnfPItF/99YdiYZupS3+gG\n2ZIcYrwZduRsfXDXX5D/2yr/fYvUWwp38VYVN8P+37cLuffVj8Me0mxdpGpVnlA1s3ZmNtvMVpnZ\nSjMbF2UfM7O/mtlaM/vIzI6rnXIl5eTlBW9+XVH5zbAD42eEBfv1px2tYBeJUSwz913Atc65JWbW\nHFhsZm8451ZV2Od0oFP5x/HA4+WfRfYvys2w7/39n/nf5elhuynUReJTZbg7574Cvir/epuZrQba\nABXD/SzgaRc8O/u+mbU0s8PLnyuyfxVuhh0YPwM27X3o+cv70ifrYI8KE0lecR1zN7MA0BNYEPFQ\nG+DzCtvF5WMKd4nJfz3xPvMLN4eNabYuUn0xh7uZNQNeBP7gnPuhOm9mZmOAMQCZmWq7KrBrdxkd\nc18NG5t3Q3/aHZxRyTNEJBYxhbuZNSIY7AXOuX9F2eULoF2F7bblY2Gcc/lAPgTXucddraSUjjfP\nZFdZ+D8DzdZFEqPKcLfgreAnA6udcw9Wstt04Pdm9hzBE6lbdbxdKhOt0dfyCYNpnt7Io4pEUk8s\nM/d+wIXAcjNbWj52M5AJ4JybBMwEhgJrgRLgksSXKqlArQNE6kYsq2XeAayKfRwwNlFFSer5eusO\nTrj3rbCxwnuGktZgv/+0RKSadIWq1LrI2fopR7dmyiV9PKpGpH5QuEutWfnlVob99Z2wMZ0wFakb\nCnepFZGz9fvOOZbze2v5q0hdUbhLQr21+hsufSq8lbNm6yJ1T+EuCRM5Wy/43fH063iIR9WI1G8K\nd6mxv7+7jjv+vSpsTLN1EW8p3KXanHNk3TQzbOzNP55Mx0Obe1SRiOyhcJdqueWl5TzzfvjdkjRb\nF/EPhbvEJVqjr0W3DOSQZo09qkhEolG4S8zOeXw+i9d/H9pud3AT5t1wqocViUhlFO5SpW07Sjl2\nQnijr4/vGkJ6ozSPKhKRqlR5D1WJQ0EBBALQoEHwc0GB1xXVWKfcmWHBfnq3wyiaOEzBLuJzCvdE\nKSiAMWNg/XpwLvh5zJikDfji70sIjJ9B6e69/dY/u2coj/+ml4dVJYEU/AEvycmCDR3rXk5Ojlu0\naFHVOyaLQCAY6JHat4eiorqupkYiL0a6ZkAn/jjoKI+qSSJ7fsCXlOwdy8iA/Py9NwIXqSEzW+yc\ny6lqP83cE2XDhvjGfWjZ51v2CfaiicMSE+z1YUabmxse7BDczs31ph6p13RCNVEyM6PP3JPkXrGR\nof6X87M5u2ebxLx45Ix2zyErSK0ZbQr8gJfUoZl7ouTlBX8FrygjIzjuY6+t+CrqbD1hwQ71Z0Zb\n2Q/yJPkBL6lFM/dE2TMDzc0NztQyM4PB7uOZaWSoP395X/pkHZz4N6ovM9q8vOjH3H3+A15Sk8I9\nkUaP9nWY7zHp7UImvvpx2Fittg5I8kNWMUvCH/CSunRYJlXEcMLSOUdg/IywYJ993Sm13xMmSQ9Z\nVcvo0cHVUWVlwc8KdvGIZu6pIIYTltc+v4wXlxSHPa3OGn1pRitS57TOPRXsZ439zrWfcdQt4Y2+\nlt42iJYZB9RNbSKSULGuc9fMPRVUcmLy9P7XsrpCsHc+rDmv/eHkuqpKRDxUZbib2ZPAcOBb51y3\nKI+fArwMrCsf+pdz7s5EFilViDhhubVxU3r84Z9hu3xy9xAaN1Q/GJH6IpaZ+xTgEeDp/ewzzzk3\nPCEVSfwqLMEL3PhK2EO/7tmGh87P9qgwEfFKleHunJtrZoHaL0WqbfRovi01+nx8YNjwunuHYmYe\nFSUiXkrUUsi+ZrbMzF41s2MS9JoSowF/nhMW7DcMOZqiicMU7CL1WCJOqC4B2jvntpvZUOAloFO0\nHc1sDDAGIDPVLmDxwNpvtzPwwbfDxnQfUxGBBIS7c+6HCl/PNLPHzOwQ59ymKPvmA/kQXApZ0/eu\nzyJbB7x45Yn0an+QR9WIiN/UONzN7DDgG+ecM7M+BA/1bK5xZRLVwqLvGDnpvdC2Gay7V7N1EQkX\ny1LIZ4FTgEPMrBi4HWgE4JybBJwLXGlmu4CfgFHOqyujUlzkbH32daeQdUhTj6oRET+LZbXMBVU8\n/gjBpZJSS2Z89BVj/7EktK2LkUSkKrpC1cecc2TdNDNsbNEtAzmkWWOPKhKRZKFw96m/zfuMu2es\nDm0PO/ZwHh19nIcViUgyUbj7TOnuMjrlhjf6WnXnaWQcoL8qEYmdEsNHJkxfyZT5RaHtq07pwA1D\nOntXkIgkLYW7D2zbUcqxE14PGyu8ZyhpDXSFqYhUj+7EFK8Y7ngUj4ue/CAs2O/59bEUTRymYBeR\nGtHMPR4x3PEoVl9v3cEJ974VNqZGXyKSKLoTUzz2c8cjiopifplf3jeL4u9/Cm1PviiHAV1+UfP6\nRCTl6U5MtaGSOx5VOh7h02+2MfihuWFjavQlIrVB4R6PiDsehY1XIbJ1wMtj+9GjXctEVSYiEia5\nTqgm+GRm3PLyICMjfCwjIzheifmFm8KCvekBaRRNHKZgF5FalTwz9wSezKy2Pe+Tmxs8FJOZGQz2\nSt4/crY+9/r+ZLbKiLqviEgiJc8J1QSdzKwLLy/9gnHPLQ1t92jXkpfH9vOwIhFJFal3QrWGJzPr\nQrRGXx/eOoiDmh7gUUUiUl8lzzH3yk5a+uR2fS8v/SIs2Ef0bEPRxGEKdhHxRPLM3PPywo+5Q5Un\nM+tCtEZfn9w9hMYN0zyqSEQkmWbuo0dDfn7wGLtZ8HN+ft2dTI0if25hWLDff253iiYOU7CLiOeS\nZ+YOwSD3MMz3+PHnXRxz+3/Cxj67ZygN1A9GRHwiucLdB6YuLua6F5aFtv9+SW/6H32ohxWJiOxL\n4R6jH3aU0r1C98YmjdJYfdcQDysSEamcwj0G+XMLuWfmx6HtOdedQuCQph5WJCKyfwr3/fh22w76\n5O1ty3vpL7O4dXhXDysSEYmNwr0SeTNW8cS8daHtD24ewKEt0j2sSEQkdlWGu5k9CQwHvnXOdYvy\nuAEPA0OBEuBi59ySRBdaV9Zv/pFf3T8ntH3jkM5ceUoH7woSEamGWGbuU4BHgKcrefx0oFP5x/HA\n4+Wfk87Ww/HKAAAFhUlEQVS45z7k5aVfhraX3T6YA5s08rAiEZHqqTLcnXNzzSywn13OAp52wQ5k\n75tZSzM73Dn3VYJqrHUrv9zKsL++E9r+07ndOS+nnYcViYjUTCKOubcBPq+wXVw+5vtwd84xKv99\nFqz7DoDm6Q1ZmDuQ9Ea6wlREkludnlA1szHAGIBMjxt+vf/ZZkblvx/afuK3OQzqqvuYikhqSES4\nfwFUPIbRtnxsH865fCAfgv3cE/Decdu1u4xBD81l3aYfAeh4aDNeG3cSDdOSp82OiEhVEhHu04Hf\nm9lzBE+kbvXr8fbXVnzNFc8sDm0/f3lf+mQd7GFFIiK1I5alkM8CpwCHmFkxcDvQCMA5NwmYSXAZ\n5FqCSyEvqa1iq2tH6W6Ou+sNSnbuBqBfx1Y8c+nxBFdxioiknlhWy1xQxeMOGJuwihLsnws3cOOL\ny0Pbr447iS6Ht/CwIhGR2peyV6huLSmlx517G32NOK4ND56X7WFFIiJ1JyXD/dHZa7n/P5+Etufd\n0J92B2d4WJGISN1KqXD/5ocdHH/P3kZfV/yqA+NP7+xhRSIi3kiZcJ8wfSVT5heFthfmDqR188be\nFSQi4qGkD/d1m36k/wNzQtu3DOvC70460ruCRER8IGnD3TnH7//xITOW711Sv3zCYJqnq9GXiEhS\nhvvy4q2c8cjeRl8PnteDEce19bAiERF/Sbpw//y7klCwt2p6AO+OP1WNvkREIiRduDdr3JB+HVtx\n6S+zOLWzGn2JiESTdOF+UNMDKPjdCV6XISLia2qFKCKSghTuIiIpSOEuIpKCFO4iIilI4S4ikoIU\n7iIiKUjhLiKSghTuIiIpyIJ3yfPgjc02Autj2PUQYFMtl5OM9H2pnL430en7Urlk+t60d861rmon\nz8I9Vma2yDmX43UdfqPvS+X0vYlO35fKpeL3RodlRERSkMJdRCQFJUO453tdgE/p+1I5fW+i0/el\ncin3vfH9MXcREYlfMszcRUQkTr4MdzNrZ2azzWyVma00s3Fe1+QnZpZmZh+a2Ste1+InZtbSzKaa\n2cdmttrM+npdk1+Y2f+U/19aYWbPmlm61zV5xcyeNLNvzWxFhbGDzewNM1tT/vkgL2tMBF+GO7AL\nuNY51xU4ARhrZl09rslPxgGrvS7Chx4GXnPOdQZ6oO8RAGbWBrgGyHHOdQPSgFHeVuWpKcCQiLHx\nwFvOuU7AW+XbSc2X4e6c+8o5t6T8620E/5O28bYqfzCztsAw4G9e1+InZnYgcDIwGcA5t9M5t8Xb\nqnylIdDEzBoCGcCXHtfjGefcXOC7iOGzgKfKv34KOLtOi6oFvgz3iswsAPQEFnhbiW/8BbgBKPO6\nEJ/JAjYCfy8/ZPU3M2vqdVF+4Jz7AngA2AB8BWx1zr3ubVW+8wvn3FflX38NJP0Nmn0d7mbWDHgR\n+INz7gev6/GamQ0HvnXOLfa6Fh9qCBwHPO6c6wn8SAr8ap0I5cePzyL4A/AIoKmZ/cbbqvzLBZcQ\nJv0yQt+Gu5k1IhjsBc65f3ldj0/0A840syLgOeBUM3vG25J8oxgods7t+Q1vKsGwFxgIrHPObXTO\nlQL/Ak70uCa/+cbMDgco//ytx/XUmC/D3cyM4LHT1c65B72uxy+cczc559o65wIET4jNcs5pBgY4\n574GPjezo8uHBgCrPCzJTzYAJ5hZRvn/rQHoZHOk6cBF5V9fBLzsYS0J4ctwJzhDvZDgzHRp+cdQ\nr4sS37saKDCzj4Bs4B6P6/GF8t9mpgJLgOUE/9+n3BWZsTKzZ4H3gKPNrNjMLgUmAoPMbA3B33Qm\nelljIugKVRGRFOTXmbuIiNSAwl1EJAUp3EVEUpDCXUQkBSncRURSkMJdRCQFKdxFRFKQwl1EJAX9\nH4hzRXuDCwNQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cfcbe196a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50\n",
    "\n",
    "# Training Data\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n",
    "# Construct a linear model\n",
    "pred = tf.add(tf.mul(X, W), b)\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "    #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost= 1.182138962\n",
      "Epoch: 0002 cost= 0.664737251\n",
      "Epoch: 0003 cost= 0.552646219\n",
      "Epoch: 0004 cost= 0.498572783\n",
      "Epoch: 0005 cost= 0.465481310\n",
      "Epoch: 0006 cost= 0.442586323\n",
      "Epoch: 0007 cost= 0.425418170\n",
      "Epoch: 0008 cost= 0.412148364\n",
      "Epoch: 0009 cost= 0.401378326\n",
      "Epoch: 0010 cost= 0.392405347\n",
      "Epoch: 0011 cost= 0.384737775\n",
      "Epoch: 0012 cost= 0.378154854\n",
      "Epoch: 0013 cost= 0.372368281\n",
      "Epoch: 0014 cost= 0.367258565\n",
      "Epoch: 0015 cost= 0.362725895\n",
      "Epoch: 0016 cost= 0.358537637\n",
      "Epoch: 0017 cost= 0.354877519\n",
      "Epoch: 0018 cost= 0.351462018\n",
      "Epoch: 0019 cost= 0.348306181\n",
      "Epoch: 0020 cost= 0.345419968\n",
      "Epoch: 0021 cost= 0.342740956\n",
      "Epoch: 0022 cost= 0.340250687\n",
      "Epoch: 0023 cost= 0.337924440\n",
      "Epoch: 0024 cost= 0.335737580\n",
      "Epoch: 0025 cost= 0.333705541\n",
      "Optimization Finished!\n",
      "Accuracy: 0.888667\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y: mnist.test.labels[:3000]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
