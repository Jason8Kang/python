{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 21:23:18,227 : INFO : collecting all words and their counts\n",
      "2017-02-23 21:23:18,230 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-23 21:23:18,232 : INFO : collected 15 word types from a corpus of 16 raw words and 2 sentences\n",
      "2017-02-23 21:23:18,233 : INFO : Loading a fresh vocabulary\n",
      "2017-02-23 21:23:18,234 : INFO : min_count=1 retains 15 unique words (100% of original 15, drops 0)\n",
      "2017-02-23 21:23:18,236 : INFO : min_count=1 leaves 16 word corpus (100% of original 16, drops 0)\n",
      "2017-02-23 21:23:18,240 : INFO : deleting the raw counts dictionary of 15 items\n",
      "2017-02-23 21:23:18,242 : INFO : sample=0.001 downsamples 15 most-common words\n",
      "2017-02-23 21:23:18,243 : INFO : downsampling leaves estimated 2 word corpus (13.7% of prior 16)\n",
      "2017-02-23 21:23:18,246 : INFO : estimated required memory for 15 words and 100 dimensions: 19500 bytes\n",
      "2017-02-23 21:23:18,247 : INFO : resetting layer weights\n",
      "2017-02-23 21:23:18,250 : INFO : training model with 3 workers on 15 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-02-23 21:23:18,253 : INFO : expecting 2 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-23 21:23:18,259 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-23 21:23:18,263 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-23 21:23:18,265 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-23 21:23:18,266 : INFO : training on 80 raw words (12 effective words) took 0.0s, 1513 effective words/s\n",
      "2017-02-23 21:23:18,267 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.037321978880052842"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "# 引入日志配置\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# 引入数据集\n",
    "sentences = [\"the quick brown fox jumps over the lazy dogs\",\"yoyoyo you go home now to sleep\"]\n",
    "\n",
    "# 切分词汇\n",
    "vocab = [s.encode('utf-8').split() for s in sentences]\n",
    "\n",
    "# 构建模型\n",
    "model = word2vec.Word2Vec(vocab, min_count=1)\n",
    "\n",
    "# 进行相关性比较\n",
    "model.similarity('dogs','you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 21:24:26,565 : INFO : collecting all words and their counts\n",
      "2017-02-23 21:24:26,569 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-23 21:24:36,894 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2017-02-23 21:24:36,897 : INFO : Loading a fresh vocabulary\n",
      "2017-02-23 21:24:37,499 : INFO : min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "2017-02-23 21:24:37,500 : INFO : min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "2017-02-23 21:24:37,818 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2017-02-23 21:24:37,861 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2017-02-23 21:24:37,865 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "2017-02-23 21:24:37,867 : INFO : estimated required memory for 71290 words and 200 dimensions: 149709000 bytes\n",
      "2017-02-23 21:24:38,316 : INFO : resetting layer weights\n",
      "2017-02-23 21:24:40,346 : INFO : training model with 3 workers on 71290 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-02-23 21:24:40,348 : INFO : expecting 1701 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-23 21:24:41,365 : INFO : PROGRESS: at 0.79% examples, 487746 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-23 21:24:42,365 : INFO : PROGRESS: at 1.60% examples, 493524 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-23 21:24:43,388 : INFO : PROGRESS: at 2.42% examples, 497376 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:24:44,381 : INFO : PROGRESS: at 3.23% examples, 499038 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:24:45,401 : INFO : PROGRESS: at 4.03% examples, 497124 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:24:46,413 : INFO : PROGRESS: at 4.82% examples, 496943 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:24:47,413 : INFO : PROGRESS: at 5.57% examples, 493257 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:24:48,426 : INFO : PROGRESS: at 6.41% examples, 496786 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:24:49,433 : INFO : PROGRESS: at 7.22% examples, 498296 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:24:50,451 : INFO : PROGRESS: at 8.07% examples, 500469 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:24:51,461 : INFO : PROGRESS: at 8.89% examples, 501541 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:24:52,470 : INFO : PROGRESS: at 9.74% examples, 503770 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:24:53,474 : INFO : PROGRESS: at 10.55% examples, 503879 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:24:54,487 : INFO : PROGRESS: at 11.38% examples, 505013 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:24:55,496 : INFO : PROGRESS: at 12.19% examples, 505063 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:24:56,506 : INFO : PROGRESS: at 13.03% examples, 505971 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:24:57,512 : INFO : PROGRESS: at 13.85% examples, 506458 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:24:58,506 : INFO : PROGRESS: at 14.65% examples, 506247 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:24:59,517 : INFO : PROGRESS: at 15.50% examples, 506308 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:00,532 : INFO : PROGRESS: at 16.34% examples, 507135 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:01,530 : INFO : PROGRESS: at 17.17% examples, 507388 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:02,546 : INFO : PROGRESS: at 18.00% examples, 507947 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:03,539 : INFO : PROGRESS: at 18.77% examples, 506366 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:04,549 : INFO : PROGRESS: at 19.56% examples, 505923 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:05,551 : INFO : PROGRESS: at 20.38% examples, 505833 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:06,562 : INFO : PROGRESS: at 21.08% examples, 503033 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:07,579 : INFO : PROGRESS: at 21.80% examples, 500549 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:08,596 : INFO : PROGRESS: at 22.61% examples, 500306 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:09,596 : INFO : PROGRESS: at 23.36% examples, 499259 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:10,604 : INFO : PROGRESS: at 24.22% examples, 500372 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:11,622 : INFO : PROGRESS: at 25.01% examples, 499931 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:12,641 : INFO : PROGRESS: at 25.82% examples, 500096 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:13,667 : INFO : PROGRESS: at 26.55% examples, 498817 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:14,664 : INFO : PROGRESS: at 27.36% examples, 499022 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:15,670 : INFO : PROGRESS: at 28.17% examples, 499190 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:16,680 : INFO : PROGRESS: at 28.99% examples, 499567 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-23 21:25:17,690 : INFO : PROGRESS: at 29.82% examples, 499970 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:18,697 : INFO : PROGRESS: at 30.63% examples, 500022 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:19,703 : INFO : PROGRESS: at 31.43% examples, 500006 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:20,716 : INFO : PROGRESS: at 32.26% examples, 500462 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:21,726 : INFO : PROGRESS: at 33.06% examples, 500433 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:22,732 : INFO : PROGRESS: at 33.89% examples, 500666 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:23,749 : INFO : PROGRESS: at 34.70% examples, 500757 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:24,755 : INFO : PROGRESS: at 35.53% examples, 500810 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:25,762 : INFO : PROGRESS: at 36.34% examples, 500733 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:26,770 : INFO : PROGRESS: at 37.19% examples, 501261 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-23 21:25:27,792 : INFO : PROGRESS: at 37.98% examples, 500886 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:28,805 : INFO : PROGRESS: at 38.67% examples, 499355 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:29,809 : INFO : PROGRESS: at 39.19% examples, 495670 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:30,823 : INFO : PROGRESS: at 39.87% examples, 494082 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:31,842 : INFO : PROGRESS: at 40.67% examples, 493998 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:32,861 : INFO : PROGRESS: at 41.53% examples, 494544 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:33,874 : INFO : PROGRESS: at 42.30% examples, 494192 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:34,878 : INFO : PROGRESS: at 43.09% examples, 494020 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:35,897 : INFO : PROGRESS: at 43.81% examples, 493044 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:36,904 : INFO : PROGRESS: at 44.62% examples, 493284 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:37,921 : INFO : PROGRESS: at 45.37% examples, 492902 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:38,924 : INFO : PROGRESS: at 46.07% examples, 491933 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:39,927 : INFO : PROGRESS: at 46.77% examples, 491104 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:40,936 : INFO : PROGRESS: at 47.54% examples, 490939 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:41,961 : INFO : PROGRESS: at 48.29% examples, 490394 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-23 21:25:42,967 : INFO : PROGRESS: at 49.03% examples, 489884 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:43,973 : INFO : PROGRESS: at 49.76% examples, 489350 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:45,006 : INFO : PROGRESS: at 50.56% examples, 489292 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:46,019 : INFO : PROGRESS: at 51.37% examples, 489500 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:47,025 : INFO : PROGRESS: at 52.20% examples, 489998 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:48,035 : INFO : PROGRESS: at 53.04% examples, 490389 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:49,046 : INFO : PROGRESS: at 53.89% examples, 490913 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:50,049 : INFO : PROGRESS: at 54.72% examples, 491375 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:51,062 : INFO : PROGRESS: at 55.59% examples, 491845 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:52,059 : INFO : PROGRESS: at 56.45% examples, 492392 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:53,068 : INFO : PROGRESS: at 57.25% examples, 492499 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:54,068 : INFO : PROGRESS: at 58.10% examples, 493029 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:55,069 : INFO : PROGRESS: at 58.93% examples, 493325 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:56,078 : INFO : PROGRESS: at 59.76% examples, 493563 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:57,086 : INFO : PROGRESS: at 60.60% examples, 493914 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:25:58,095 : INFO : PROGRESS: at 61.47% examples, 494410 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:25:59,108 : INFO : PROGRESS: at 62.28% examples, 494464 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:00,107 : INFO : PROGRESS: at 63.13% examples, 494886 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:01,114 : INFO : PROGRESS: at 63.97% examples, 495234 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:02,115 : INFO : PROGRESS: at 64.80% examples, 495526 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:03,125 : INFO : PROGRESS: at 65.63% examples, 495820 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:04,138 : INFO : PROGRESS: at 66.49% examples, 496326 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-23 21:26:05,157 : INFO : PROGRESS: at 67.33% examples, 496639 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:06,157 : INFO : PROGRESS: at 68.17% examples, 496967 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:07,171 : INFO : PROGRESS: at 69.01% examples, 497200 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:08,187 : INFO : PROGRESS: at 69.85% examples, 497566 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:09,197 : INFO : PROGRESS: at 70.68% examples, 497721 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-23 21:26:10,196 : INFO : PROGRESS: at 71.52% examples, 498047 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:11,200 : INFO : PROGRESS: at 72.35% examples, 498234 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:12,223 : INFO : PROGRESS: at 73.20% examples, 498571 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:13,234 : INFO : PROGRESS: at 74.04% examples, 498734 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:14,234 : INFO : PROGRESS: at 74.89% examples, 499100 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:15,243 : INFO : PROGRESS: at 75.72% examples, 499114 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:16,255 : INFO : PROGRESS: at 76.58% examples, 499456 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:17,252 : INFO : PROGRESS: at 77.41% examples, 499660 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:18,263 : INFO : PROGRESS: at 78.24% examples, 499770 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:19,272 : INFO : PROGRESS: at 79.08% examples, 500030 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:20,280 : INFO : PROGRESS: at 79.94% examples, 500285 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:21,292 : INFO : PROGRESS: at 80.78% examples, 500422 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:22,298 : INFO : PROGRESS: at 81.59% examples, 500383 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:23,305 : INFO : PROGRESS: at 82.42% examples, 500525 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:24,311 : INFO : PROGRESS: at 83.28% examples, 500830 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:25,319 : INFO : PROGRESS: at 84.10% examples, 500950 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:26,315 : INFO : PROGRESS: at 84.94% examples, 501171 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:27,325 : INFO : PROGRESS: at 85.73% examples, 501103 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:28,336 : INFO : PROGRESS: at 86.57% examples, 501427 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-23 21:26:29,332 : INFO : PROGRESS: at 87.20% examples, 500422 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:30,342 : INFO : PROGRESS: at 87.98% examples, 500318 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:31,349 : INFO : PROGRESS: at 88.81% examples, 500449 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:32,349 : INFO : PROGRESS: at 89.61% examples, 500441 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:33,351 : INFO : PROGRESS: at 90.36% examples, 500175 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:34,371 : INFO : PROGRESS: at 91.18% examples, 500261 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:35,381 : INFO : PROGRESS: at 92.00% examples, 500355 words/s, in_qsize 6, out_qsize 1\n",
      "2017-02-23 21:26:36,390 : INFO : PROGRESS: at 92.82% examples, 500376 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:37,404 : INFO : PROGRESS: at 93.57% examples, 500057 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:38,421 : INFO : PROGRESS: at 94.37% examples, 500042 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:39,423 : INFO : PROGRESS: at 95.20% examples, 500108 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:40,437 : INFO : PROGRESS: at 96.04% examples, 500163 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:41,447 : INFO : PROGRESS: at 96.87% examples, 500334 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:42,447 : INFO : PROGRESS: at 97.72% examples, 500540 words/s, in_qsize 5, out_qsize 0\n",
      "2017-02-23 21:26:43,463 : INFO : PROGRESS: at 98.47% examples, 500210 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:44,490 : INFO : PROGRESS: at 99.31% examples, 500262 words/s, in_qsize 6, out_qsize 0\n",
      "2017-02-23 21:26:45,301 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-23 21:26:45,312 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-23 21:26:45,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-23 21:26:45,316 : INFO : training on 85026035 raw words (62530378 effective words) took 125.0s, 500386 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29891614553377199"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "# 引入日志配置\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# 引入数据集\n",
    "sentences = word2vec.Text8Corpus('text8')\n",
    "\n",
    "# 构建模型\n",
    "model = word2vec.Word2Vec(sentences,size=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 21:27:24,973 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'queen', 0.6741054058074951)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'queen', 0.6741054058074951), (u'throne', 0.5814212560653687)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'woman', 0.6959283351898193),\n",
       " (u'girl', 0.5780448913574219),\n",
       " (u'person', 0.548554539680481),\n",
       " (u'boy', 0.536231517791748),\n",
       " (u'creature', 0.5331358909606934),\n",
       " (u'evil', 0.5013101100921631),\n",
       " (u'stranger', 0.4998752176761627),\n",
       " (u'men', 0.49986177682876587),\n",
       " (u'gentleman', 0.49979591369628906),\n",
       " (u'god', 0.4852331578731537)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 21:34:25,979 : INFO : saving Word2Vec object under text8.model, separately None\n",
      "2017-02-23 21:34:25,980 : INFO : storing np array 'syn0' to text8.model.wv.syn0.npy\n",
      "2017-02-23 21:34:26,127 : INFO : storing np array 'syn1neg' to text8.model.syn1neg.npy\n",
      "2017-02-23 21:34:26,275 : INFO : not storing attribute syn0norm\n",
      "2017-02-23 21:34:26,276 : INFO : not storing attribute cum_table\n",
      "2017-02-23 21:34:27,661 : INFO : saved text8.model\n"
     ]
    }
   ],
   "source": [
    "model.save('text8.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 21:34:50,780 : INFO : loading Word2Vec object from text8.model\n",
      "2017-02-23 21:34:51,312 : INFO : loading wv recursively from text8.model.wv.* with mmap=None\n",
      "2017-02-23 21:34:51,315 : INFO : loading syn0 from text8.model.wv.syn0.npy with mmap=None\n",
      "2017-02-23 21:34:51,362 : INFO : loading syn1neg from text8.model.syn1neg.npy with mmap=None\n",
      "2017-02-23 21:34:51,414 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-02-23 21:34:51,414 : INFO : setting ignored attribute cum_table to None\n",
      "2017-02-23 21:34:51,417 : INFO : loaded text8.model\n"
     ]
    }
   ],
   "source": [
    "model1 = word2vec.Word2Vec.load('text8.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 21:34:54,697 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'mother', 0.7641723155975342),\n",
       " (u'grandmother', 0.7064921855926514),\n",
       " (u'wife', 0.6959325075149536)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.most_similar(['girl', 'father'], ['boy'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_examples = [\"he is she\", \"big bigger bad\", \"going went being\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'he' is to 'is' as 'she' is to 'exists'\n",
      "'big' is to 'bigger' as 'bad' is to 'worse'\n",
      "'going' is to 'went' as 'being' is to 'was'\n"
     ]
    }
   ],
   "source": [
    "for example in more_examples:\n",
    "    a, b, x = example.split()\n",
    "    predicted = model.most_similar([x, b], [a])[0][0]\n",
    "    print \"'%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98775482,  1.65721357, -1.16629601,  1.58299041, -0.140579  ,\n",
       "        1.44986999, -0.20340316,  0.32260802, -0.1148894 , -2.39717746,\n",
       "       -0.07748767,  1.752321  ,  0.18233523,  0.3592658 ,  0.25676116,\n",
       "       -1.26959932,  0.81998515, -1.53029072, -2.08956623,  0.67615718,\n",
       "        2.67316461, -0.99789733,  1.90129256, -1.02994239, -0.28002632,\n",
       "        1.42542839, -1.07206523,  0.25403276, -2.27353048,  0.60330921,\n",
       "        0.4973526 , -0.12400388, -0.90536755, -0.48453701,  0.6971966 ,\n",
       "       -0.10278421,  3.97962356, -0.72127008, -1.05371511, -1.54193425,\n",
       "       -0.95113659, -0.70543885, -2.47150922, -1.20587051,  2.5953176 ,\n",
       "        0.33366737,  3.27115655,  1.10872447,  0.10064077, -2.00080276,\n",
       "       -1.07754207, -0.51561403, -0.00595231, -0.33686537, -0.27632803,\n",
       "        0.65668786, -0.23705308, -1.19250143,  0.47357082, -1.53105319,\n",
       "       -1.93190289, -0.97836775, -0.79306406,  1.21991646, -1.69496512,\n",
       "        1.84437835, -0.18739304, -1.12510324,  1.77240205,  0.2291536 ,\n",
       "        0.16679472, -0.52852857,  1.01918745,  0.81293988, -1.04173458,\n",
       "       -2.31207657,  0.50254464,  0.16242859, -0.73224849,  1.44314957,\n",
       "        0.55067074, -1.40501642, -1.60407162, -0.44895613,  0.02379936,\n",
       "        1.98239684,  0.44531238, -0.69717854, -0.88052702,  0.46242028,\n",
       "       -0.4409703 ,  0.03249888,  1.04317141, -1.15544879,  0.11457547,\n",
       "        0.4007014 , -2.19163394, -1.27485633,  0.01075914,  1.44605732,\n",
       "        0.67690229, -1.73541784, -0.51702589, -1.33422565,  0.59518164,\n",
       "        0.33664721, -0.63660491,  0.56975943, -1.69548583, -0.31489432,\n",
       "       -1.99788558, -0.74726176,  0.14782783,  1.96084356, -1.56063581,\n",
       "       -0.66357976,  0.41427979, -0.26762524,  0.62049842, -0.7273072 ,\n",
       "        0.11654719,  1.33833015, -1.27587867,  1.32427549,  0.90571445,\n",
       "       -0.82232952,  0.59997684,  0.24582566,  0.56176978, -0.22344492,\n",
       "       -0.80342454,  0.93988007, -0.99415505, -0.00963684, -0.386383  ,\n",
       "        0.24408311, -0.2265036 , -1.56773043,  0.3190212 ,  1.7085253 ,\n",
       "       -1.54839337, -0.76439887,  1.33489513,  1.70456839,  0.91979557,\n",
       "        2.45920777, -0.97048336,  0.91573787, -0.06301682,  1.67602158,\n",
       "        0.10965534, -0.25311804,  0.21222644, -2.40235162,  0.74586946,\n",
       "       -0.2990928 , -0.34821916, -0.15969588,  2.21175337, -0.071077  ,\n",
       "        0.41274846,  0.04647739, -2.06831574,  0.41882819, -0.01329553,\n",
       "        0.57149786, -1.45507979,  1.73778975,  1.1796751 , -0.11350281,\n",
       "       -0.93340552, -2.35136366,  1.52004349,  0.99401766,  1.21229577,\n",
       "        0.54347175,  1.70478094,  0.86273402, -1.49947309,  3.38692617,\n",
       "       -0.10816699,  1.74353683, -0.58567572,  0.53594351, -0.44813624,\n",
       "        0.7523126 ,  0.45867071, -1.91761482, -0.01952028, -0.21318077,\n",
       "       -0.63062966, -1.37056625,  1.07016444, -0.66688257,  0.29620007,\n",
       "       -0.39351788,  1.65946114,  1.09574974, -1.24554229, -0.03337253], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1[\"computer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
